* Molecular hydrogen lines at optical wavelengths
- Now that we have established that the DRLs are actually H2, we can see what physics we can do with them



** Analysis of identified lines in NGC 346

*** Read in the spreadsheet data from Google sheets
- File is exported to
  - [[file:../data/spec1d/H2 DRL identifications from Cloudy.xlsx]]
- We convert them into a bunch of YAML files
- [2023-08-05 Sat] Now we get the blend rows as well
#+begin_src python :tangle ../scripts/h2-spreadsheet-convert.py
  import pandas as pd
  import sys
  from pathlib import Path
  import typer
  import openpyxl
  import yaml
  import slugify

  def main(
          excel_file: str,
          out_folder: str="n346-lines",
  ):
      """Convert excel spreadsheet of emission lines to YAML files, one per row

      Preserves Notes and Comments on each cell
      """
      # Read in the spreadsheet
      workbook = openpyxl.load_workbook(excel_file, data_only=True)
      # And select the first sheet
      sheet = workbook.active

      # Make a list of row data from the sheet
      values_array = list(sheet.values)

      # Make sure the output folder exists
      out_path = Path(out_folder)
      out_path.mkdir(parents=True, exist_ok=True)

      # Column headers are in first row
      kwds = [
          # Try to make sure headers are valid identifiers
          slugify.slugify(str(x), lowercase=False, separator="_", replacements=[["Î»", "lambda"]])
          for x in values_array[0]
          # And skip empty columns
          if x
      ]
      # sys.exit(str(kwds))

      # Loop over all the following rows
      for index, values in enumerate(values_array[1:], start=2):
          if not any(values):
              # Skip any blank rows
              continue
          # Make a dict of the data from this row
          data = dict(zip(kwds, values))
          # Save row number in the Google Sheet for cross-referencing of blends
          data["H2_index"] = index
          # For any lines that do not have an observed counterpart ...
          if not data["wl_obs"]:
              # ... check if they are blends with next or previous
              if data["Notes"] and data["Notes"].startswith("blend with"):
                  # save pointers  to the line they are blended with
                  if "blend with prev" in data["Notes"]:
                      data["blend_index"] = index - 1
                  elif "blend with next" in data["Notes"]:
                      data["blend_index"] = index + 1
                  else:
                      continue
              else:
                  # ... othewise skip
                  continue
          # rovib quantum numbers of upper and lower states
          vhi, vlo = int(data["Vhi"]), int(data["Vlo"])
          jhi, jlo = int(data["Jhi"]), int(data["Jlo"])
          # Make a string for the transition
          transition = f"{vhi:02d}_{jhi:02d}-{vlo:02d}_{jlo:02d}"
          wavstring = slugify.slugify(data["wl_lab"], separator="")
          # Save the data to a YAML file
          with open(out_path / f"{index:04d}-{transition}-{wavstring}.yaml", "w") as f:
              yaml.dump(data, f, allow_unicode=True, sort_keys=False, default_flow_style=False)



  if __name__ == "__main__":
      typer.run(main)

#+end_src

#+begin_src sh :dir ../data :results verbatim
  python ../scripts/h2-spreadsheet-convert.py "spec1d/H2 DRL identifications from Cloudy.xlsx" --out-folder n346-h2-lines
#+end_src

#+RESULTS:

*** Merge the H2 ids with the unidentified list

**** First, we switch the yaml files to a pandas data frame
#+begin_src python :eval no :tangle ../scripts/h2-collate-lines.py
  import numpy as np
  import yaml
  from pathlib import Path
  import pandas as pd
  import typer
  import sys

  def main(data_dir: str="n346-h2-lines"):
        # Next, get all the lines into a big list of dicts
        line_files = sorted(Path(data_dir).glob("*.yaml"))
        data = [
              yaml.safe_load(path.open()) for path in line_files
        ]
        df0 = pd.DataFrame(data)
        df0.to_csv(Path(data_dir) / "h2-line-ids.csv")

  if __name__ == "__main__":
      typer.run(main)

#+end_src

#+begin_src sh :dir ../data :results none
  python ../scripts/h2-collate-lines.py
#+end_src

This writes the results to [[file:../data/n346-h2-lines/h2-line-ids.csv]]

**** Combine the H2 ids with the previous table of UILs
- This uses the uil-final-table.csv that we generated in [[id:8CCFF185-E205-42F0-9278-4E46DE184262][Make a table of rest wavelengths plus uncertainties of all the UILs]] of [[file:ngc-346-drl-spectra.org][file:~/Dropbox/muse-hii-regions/docs/ngc-346-drl-spectra.org]]
- We use ~pd.merge_asof()~ to do a fuzzy join on the wavelength column
  - This is necessary since an exact join had corner cases with rounding problems (e.g., 0.99 vs 1.00)
- We filter out the blend rows for this case, since we cannot easily deal with them
#+begin_src python :eval no :tangle ../scripts/h2-combine-tables.py
  import numpy as np
  import yaml
  from pathlib import Path
  import pandas as pd
  import typer
  import sys
  COLS = ["H2_line", "wl_lab", "wl_obs", "Notes"]
  def main(
              data_dir: str="n346-h2-lines",
              orig_data_dir: str="n346-lines/all-lines-c007-chop-mean",
  ):
        df1 = pd.read_csv(Path(orig_data_dir) / "uil-final-table.csv")
        df2 = pd.read_csv(Path(data_dir) / "h2-line-ids.csv")
        df2 = df2[COLS].sort_values("wl_obs").dropna(subset=["wl_obs"])
        df0 = pd.merge_asof(df1, df2, left_on="wave0", right_on="wl_obs", direction="nearest", tolerance=1.0)
        df0.to_csv(Path(data_dir) / "h2-final-table.csv")
        print(df0)

  if __name__ == "__main__":
      typer.run(main)

#+end_src

#+begin_src sh :dir ../data :results output verbatim
  COLUMNS=1000 python ../scripts/h2-combine-tables.py
#+end_src

#+RESULTS:
#+begin_example
     Index        wave0  sig_wave0      flux  sig_flux            Type  blend     I / 0             E(I / 0)     II / 0            E(II / 0)  MYSO / 0          E(MYSO / 0)    H2_line    wl_lab   wl_obs           Notes
0     1146  6029.569455   0.514152  0.030460  0.004393   Deep Neutral?  False  0.806796   0.2783544695494928   0.662888                    <  0.566409  0.10944291146839161   7-2 S(7)  6029.57A  6029.57             NaN
1     1153  6037.396888   0.514820  0.041788  0.003967   Deep Neutral?  False  0.477559                    <   0.453518                    <  0.621762  0.14597441811223902   7-2 S(1)  6037.46A  6037.40             NaN
2     1190  6083.195649   0.518725  0.010027  0.004825        Neutral?  False  1.655362                    <   1.854600                    <  1.587017   0.7719142568089383   7-2 S(0)  6083.08A  6083.20             NaN
3     1300  6221.819532   0.530546  0.044434  0.002802    Deep Neutral  False  0.253526                    <   0.543340                    <  0.646933  0.08354545607085527   4-0 S(5)  6221.63A  6221.82             NaN
4     1332  6261.684680   0.533945  0.027879  0.002361   Deep Neutral?  False  2.198663  0.29708825322477167   0.453927  0.10180843302574635  0.528582   0.3176379358431232  12-5 S(1)  6261.73A  6261.68   High T(excit)
..     ...          ...        ...       ...       ...             ...    ...       ...                  ...        ...                  ...       ...                  ...        ...       ...      ...             ...
109   3640  9145.250748   0.470866  0.173619  0.022533    Deep Neutral  False  0.250861                    <   0.245631  0.10120057582603312  0.499748  0.25571329399302484   9-5 S(1)  9145.66A  9145.25             NaN
110   3649  9155.283022   0.780688  0.091543  0.017510   Deep Neutral?  False  0.343321  0.12688119030418255   0.285899  0.08124287479567108  0.145526                    <   4-1 Q(4)  9155.56A  9155.28             NaN
111   3654  9162.896677   0.781337  0.033448  0.008285   Deep Neutral?  False  0.508610                    <  19.891807                    <  0.364105                    <   9-5 S(7)  9162.58A  9162.90             NaN
112   3736  9264.376659   0.789990  0.040371  0.006785  Deep Neutral??  False  0.758882  0.45368481338933114   0.234097  0.06263303203717613  0.624451  0.29546207986604506   9-5 S(8)  9264.11A  9264.38             NaN
113   3762  9297.368030   0.274485  0.249847  0.007631   Deep Neutral?  False  0.515155                    <   0.215652                    <  0.798834  0.07081402869730503   4-1 O(2)  9297.59A  9297.37  blend 8-4 Q(8)

[114 rows x 17 columns]
#+end_example

**** Write a latex table of all the H2 lines
- This is a repeat of [[id:028D1B5F-C4A1-4689-83FB-4B1FA7FB6F60][Write a latex version of the table]] in [[file:ngc-346-drl-spectra.org]]
- But with extra columns for the line label and rest wavelength


#+begin_src python :eval no :tangle ../scripts/convert-table-h2-latex.py
  import pandas as pd
  import numpy as np


  def format_blend(value, dp=2):
      if not value or not np.isfinite(value):
          return "0.0:"
      try:
          return str(round(float(value), dp)) + ":"
      except TypeError:
          return "0.0:"

  def format_float(value, dp):
      return f"{round(float(value), dp):.{dp}f}"

  def format_pair(value, uncertainty, dp=2):
      if not value or not np.isfinite(value):
          return "0.0"
      try:
          svalue = str(round(float(value), dp))
      except TypeError:
          svalue = "0.0"

      if uncertainty in ["<", ">"]:
          return f"{uncertainty} {svalue}"

      try:
          suncertainty = str(round(float(uncertainty), dp))
      except TypeError:
          suncertainty = "0.0"

      return rf"{svalue} \pm {suncertainty}"


  df = pd.read_csv("h2-final-table.csv")
  table = []
  for _, row in df.iterrows():
      if row["blend"]:
          table.append(
              {
                  r"\lambda(\text{obs})": format_blend(row["wave0"]),
                  r"Transition": row["H2_line"],
                  r"\lambda(\text{rest})": format_float(str(row["wl_lab"]).rstrip("A"), dp=2),
                  r"I(\hb = 100)": format_blend(row["flux"], 3),
                  r"\mathrm{I / 0}": "",
                  r"\mathrm{II / 0}": "",
                  r"\mathrm{MYSO / 0}": "",
              }
          )
      else:
          table.append(
              {
                  r"\lambda(\text{obs})": format_pair(row["wave0"], row["sig_wave0"]),
                  r"Transition": row["H2_line"],
                  r"\lambda(\text{rest})": format_float(str(row["wl_lab"]).rstrip("A"), dp=2),
                  r"I(\hb = 100)": format_pair(row["flux"], row["sig_flux"], 3),
                  r"\mathrm{I / 0}": format_pair(row["I / 0"], row["E(I / 0)"]),
                  r"\mathrm{II / 0}": format_pair(row["II / 0"], row["E(II / 0)"]),
                  r"\mathrm{MYSO / 0}": format_pair(
                      row["MYSO / 0"], row["E(MYSO / 0)"]
                  ),
              }
          )
      dff = pd.DataFrame(table)  

  s = dff.style.hide()


  with open("h2-final-table.tex", "w") as f:
      f.write(
          s.to_latex(
              hrules=True,
              siunitx=False,
              environment="longtable",
              column_format="RrR RRRR",
          )
      )
#+end_src

#+begin_src sh :dir ../data/n346-h2-lines :results output verbatim
  python ../../scripts/convert-table-h2-latex.py
#+end_src

#+RESULTS:

*** Merge the H2 lines with the full line list
- I am thinking that instead of giving two tables (H2 lines, then atomic/ionic lines) it would be better to put everything in a single table


**** DONE Make a table of known lines plus H2 lines
CLOSED: [2023-08-05 Sat 21:39]
- So this is a variation on [[id:58DE61EF-5582-4FC5-AE48-BB29BFA9953C][Make a table of all the known lines]] in [[file:ngc-346-drl-spectra.org]]
- The first change is to stop dropping the UIL entries
  - Instead, we will look for H2 identifications for them
- Also, we merge with the theoretical H2 lines table
- And construct the spectroscopic IDs for the lines
- We are now well-placed for dealing with the blends, which we will do when we export the latex table below
- Note that some of the lines do not get picked up
  - 8858 is severely blended with an H I line and had previously been dropped from paper
    - probably 5-2 S(8) 8859.59A
  - 9234 likewise
    - probably 9-5 S(0) 9232.94A
  - 8695 was always dubious (marked as Neutral instead of Deep Neutral)
    - from comparison with Orion, I suspected it might be [Co II] 8695.33 (or may be [Fe II])
    - See [[id:18154C16-4EAF-4D0E-AE12-0AE529FAA064][Comparison of brightnesses]] in [[file:ngc-346-drl-discuss.org]]
    - Although [Co II] fails the multiplet test, since 9146 is not observed
    - Best to drop it
  - We have a problem with the observed wavelengths
    - I changed it to plot the H2 intensity for more zones, but these do not have accurate rest wavelengths, which then causes knock-on consequences for the fuzzy matching


#+begin_src python :eval no :tangle ../scripts/make-table-known-lines-with-h2.py
  from pathlib import Path
  import yaml
  import pandas as pd
  import numpy as np
  import pyneb as pn
  import typer
  import astropy.constants as const  # type: ignore
  import astropy.units as u  # type: ignore

  LIGHT_SPEED_KMS = const.c.to(u.km / u.s).value
  UNWANTED_ZONES = ["zone-S"]
  UNWANTED_TYPES = ["Unidentified"]

  REPLACEMENTS = {
      "Deep": "Deep Neutral",
      "Fe": "Fe-Ni-Ca-Si",
  }
  BEST_TYPES = {
      "zone-0": ["Deep", "Neutral"],
      "zone-I": ["Neutral"],
      "zone-II": ["Low"],
      "zone-III": ["Med"],
      "zone-IV": ["High"],
      "zone-MYSO": ["Deep", "Neutral", "Fe"],
      "zone-S": ["Med"],
  }
  ACCEPTABLE_TYPES = {
      "zone-0": ["Deep", "Neutral", "Low", "Med", "Fe"],
      "zone-I": ["Deep", "Neutral", "Low", "Med", "Fe"],
      "zone-II": ["Deep", "Neutral", "Low", "Med", "Fe"],
      "zone-III": ["Low", "Med", "Fe", "High"],
      "zone-IV": ["Med", "High"],
      "zone-MYSO": ["Deep", "Neutral", "Low", "Med", "Fe"],
      "zone-S": ["Med"],
  }
  H2_COLS = ["H2_line", "wl_lab", "wl_obs", "Notes", "H2_index"]

  # Find intrinsic Balmer decrement
  hi = pn.RecAtom("H", 1)
  tem, den = 12500, 100
  R0 = hi.getEmissivity(tem, den, wave=6563) / hi.getEmissivity(tem, den, wave=4861)
  # Set up reddening law for SMC
  rc = pn.RedCorr()
  rc.R_V = 2.74
  rc.FitzParams = [-4.96, 2.26, 0.39, 0.6, 4.6, 1.0]
  rc.law = "F99"

  
  def main(
      id_label: str,
      debug: bool = False,
      minimum_signal_noise: float = 3.0,
      zone_file: str = "zones.yaml",
      h2_data_dir: str = "n346-h2-lines",
      orig_data_dir: str = "n346-lines",
      vsys: float = 171.1,
      d_vsys: float = 5.0,
  ):
      """Table of all identified lines"""

      # Load the zone database
      with open(Path(orig_data_dir) / zone_file) as f:
          # But drop zones we do not want
          zones = [_ for _ in yaml.safe_load(f) if _["label"] not in UNWANTED_ZONES]

      # Iterate over the zones
      wstrings = []
      fstrings = []
      for jzone, zone in enumerate(zones):
          # Read in the velocity table
          df = pd.read_csv(
              Path(orig_data_dir) / f"all-lines-{id_label}/{zone['label']}-velocities.csv"
          ).set_index("Index")
          if zone == zones[0]:
              # Initialize the output table
              df0 = df[["Type", "ID", "blend"]]
              # And a parallel shadow table for using only the best zones for determing the waves
              df00 = df[["Type", "ID", "blend"]]
          # Columns of wavelength and flux for each zone, with their respective errors
          eflux = df.flux / df.s_n
          zstring = zone["label"].split("-")[1]
          flabel = f"F({zstring})"
          elabel = f"E({zstring})"
          wlabel = f"W({zstring})"
          dwlabel = f"dW({zstring})"
          # Save a list of the wavelength columns
          wstrings.append(wlabel)
          fstrings.append(flabel)
          # Calculate the reddening correction from H alpha, which is channel 1573
          obs_decrement = df.loc[1573].flux / 100.0
          rc.setCorr(obs_decrement / R0, wave1=6563, wave2=4861)
          correction = rc.getCorr(df.wave) / rc.getCorr(df.loc[211].wave)
          # Add the 2 flux columns to the output table
          df0 = df0.assign(
              ,**{
                  flabel: correction * df.flux,
                  elabel: correction * eflux,
              }
          )
          # And the fluxes and waves to thje shadow table
          df00 = df00.assign(
              ,**{
                  wlabel: df.wave / (1 + vsys / LIGHT_SPEED_KMS),
                  dwlabel: df.e_wave,
                  flabel: correction * df.flux,
                  elabel: correction * eflux,
              }
          )
          # Ignore values with s/n that is too low or that are not acceptable types for this zone
          mask = (df.s_n < minimum_signal_noise) | ~df.Type.str.startswith(
              tuple(ACCEPTABLE_TYPES[zone["label"]])
          )
          for label in [flabel, elabel]:
              df0.loc[mask, label] = np.nan
          # Repeat for the shadow table, but only allowing the BEST types
          mask00 = (df.s_n < minimum_signal_noise) | ~df.Type.str.startswith(
              tuple(BEST_TYPES[zone["label"]])
          )
          for label in [wlabel, dwlabel, flabel, elabel]:
              df00.loc[mask00, label] = np.nan
      # Second pass: consolidate to a single wavelength column
      dwstrings = ["d" + _ for _ in wstrings]
      # Weighted average over valid zones
      df0.insert(
          4,
          "wave",
          np.nanmean(df00[wstrings].to_numpy(), axis=1),
      )
      # And use the smallest for wave error
      df0.insert(5, "e_wave", np.nanmin(df00[dwstrings], axis=1))
      # And drop lines with no wavelength
      df0 = df0[np.isfinite(df0.wave)]

      #
      # Add in the H2 lines
      #

      df2 = pd.read_csv(Path(h2_data_dir) / "h2-line-ids.csv")
      df2 = df2[H2_COLS].sort_values("wl_obs").dropna(subset=["wl_obs"])
      df0 = pd.merge_asof(
          df0, df2, left_on="wave", right_on="wl_obs", direction="nearest", tolerance=2.0
      ).set_index(df0.index)
      # Select the lines formerly unidentified
      h2mask = df0.ID.str.startswith("UIL")

      # Construct the ID description for the H2 lines
      df0.loc[h2mask, "ID"] = (
          "H_2 " + df0.loc[h2mask, "H2_line"] + " " + df0.loc[h2mask, "wl_lab"]
      )
      # And remove the extraneous columns
      df0 = df0.drop(columns=["H2_line", "wl_lab"])

      # And the entries with empty ID fields
      df0 = df0.dropna(subset="ID")

      print(df0.loc[h2mask])
      df0.to_csv(Path(h2_data_dir) / "known-lines-with-h2-final-table.csv")


  if __name__ == "__main__":
      typer.run(main)
#+end_src

#+begin_src sh :dir ../data :results output verbatim
  COLUMNS=1000 python ../scripts/make-table-known-lines-with-h2.py c007-chop-mean --minimum-signal-noise 1.0
#+end_src

#+RESULTS:
#+begin_example
                 Type                      ID  blend      F(0)         wave    e_wave      E(0)      F(I)      E(I)     F(II)     E(II)  F(III)  E(III)  F(IV)  E(IV)   F(MYSO)   E(MYSO)   wl_obs           Notes  H2_index
Index                                                                                                                                                                                                                       
1146    Deep Neutral?   H_2 7-2 S(7) 6029.57A  False  0.026172  6029.501644  0.160755  0.003774  0.022136  0.006938       NaN       NaN     NaN     NaN    NaN    NaN  0.014860  0.001911  6029.57             NaN     173.0
1153    Deep Neutral?   H_2 7-2 S(1) 6037.46A  False  0.035879  6037.212893  0.118675  0.003406       NaN       NaN       NaN       NaN     NaN     NaN    NaN    NaN  0.022362  0.004802  6037.40             NaN     175.0
1190         Neutral?   H_2 7-2 S(0) 6083.08A  False  0.008571  6083.532257  0.087536  0.004125       NaN       NaN       NaN       NaN     NaN     NaN    NaN    NaN  0.013754  0.000963  6083.20             NaN     180.0
1300     Deep Neutral   H_2 4-0 S(5) 6221.63A  False  0.037499  6221.804241  0.078828  0.002365       NaN       NaN       NaN       NaN     NaN     NaN    NaN    NaN  0.023332  0.002593  6221.82             NaN     199.0
1332    Deep Neutral?  H_2 12-5 S(1) 6261.73A  False  0.023445  6262.122680  0.105880  0.001986  0.054400  0.005727  0.010512  0.002108     NaN     NaN    NaN    NaN  0.012425  0.007392  6261.68   High T(excit)     205.0
...               ...                     ...    ...       ...          ...       ...       ...       ...       ...       ...       ...     ...     ...    ...    ...       ...       ...      ...             ...       ...
3640     Deep Neutral   H_2 9-5 S(1) 9145.66A  False  0.124354  9144.056929  0.162228  0.016139       NaN       NaN  0.027893  0.010907     NaN     NaN    NaN    NaN  0.062477  0.030923  9145.25             NaN     686.0
3649    Deep Neutral?   H_2 4-1 Q(4) 9155.56A  False  0.065545  9155.283022  0.239097  0.012537  0.024967  0.007895  0.017110  0.003596     NaN     NaN    NaN    NaN       NaN       NaN  9155.28             NaN     688.0
3654    Deep Neutral?   H_2 9-5 S(7) 9162.58A  False  0.023943  9162.896677  0.309601  0.005930       NaN       NaN       NaN       NaN     NaN     NaN    NaN    NaN       NaN       NaN  9162.90             NaN     691.0
3736   Deep Neutral??   H_2 9-5 S(8) 9264.11A  False  0.028802  9263.615044  0.210080  0.004841  0.024279  0.013929  0.006150  0.001280     NaN     NaN    NaN    NaN  0.018082  0.007998  9264.38             NaN     708.0
3762    Deep Neutral?   H_2 4-1 O(2) 9297.59A  False  0.178056  9297.275883  0.038180  0.005439       NaN       NaN       NaN       NaN     NaN     NaN    NaN    NaN  0.140809  0.011693  9297.37  blend 8-4 Q(8)     711.0

[113 rows x 20 columns]
#+end_example



**** DONE Write big LaTeX table of all the lines including H2
CLOSED: [2023-08-08 Tue 13:42]
- This is similar to [[id:F515520D-7BDD-475A-A1F7-283B5C387F29][Write latex version of the known lines table]] in [[file:ngc-346-drl-spectra.org]]
- But based on the table generated above, which includes the H_2 lines
- But the difference is that we now have another source of data for the blends
  - As well as the blend info that comes from the original big line list, we have the additional H_2 blends that come from the Cloudy output
- [X] We want to skip any blends that are predicted to be very weak (say < 0.1 of target line)
- [X] We also want to add in for the sky lines the equivalent wavelength in the nebula frame, and then that is what we sort on
- This program now has a lot of messy logic and special cases, but it does seem to work!

#+begin_src python :eval no :tangle ../scripts/convert-table-known-lines-with-h2-latex.py
  import pandas as pd
  import numpy as np
  from pathlib import Path
  import yaml
  import re
  import string

  # List of labels for blends
  LETTERS = list(string.ascii_lowercase) + [
      f"{a}{b}" for a in string.ascii_lowercase for b in string.ascii_lowercase
  ]
  # Reversed so we can use it as a stack
  LETTERS.reverse()

  ORIG_DATA_PATH = Path.cwd().parent / "n346-lines/all-lines-c007-chop-mean"

  VSYS = 171.1

  MINIMUM_H2_BLEND_STRENGTH = 0.1


  def format_blend(value, dp=2):
      if not value or not np.isfinite(value):
          return "0.0:"
      try:
          return str(round(float(value), dp)) + ":"
      except TypeError:
          return "0.0:"


  def format_float(value, dp):
      return f"{round(float(value), dp):.{dp}f}"


  def format_pair(value, uncertainty, dp=2):
      if not value or not np.isfinite(value):
          return ""
      try:
          svalue = format_float(value, dp)
      except TypeError:
          svalue = ""

      if uncertainty in ["<", ">"]:
          return f"{uncertainty} {svalue}"

      # Special case of H beta has no uncertainty
      if svalue == "100.00":
          return f"{svalue}"

      try:
          suncertainty = format_float(uncertainty, dp)
      except TypeError:
          suncertainty = ""

      return rf"{svalue} \pm {suncertainty}"


  def format_ion(ion):
      """Convert naive representation to latex version"""
      # Short circuit for sky lines
      if "OH" in ion:
          return r"Sky OH"

      if "O_2" in ion:
          return r"Sky \chem{O_2}"

      if ion.startswith("H_2"):
          molecule, transition = ion.split(maxsplit=1)
          return rf"\chem{{{molecule}}} {transition}"

      # Strip off any surrounding brackets
      prefix, suffix = "", ""
      if ion.startswith("["):
          ion = ion[1:]
          prefix = "["
      if ion.endswith("]"):
          ion = ion[:-1]
          suffix = "]"
      # And just in case of extra brackets
      ion = ion.strip("[]")
      # Split into element, stage
      element, stage = ion.rsplit(maxsplit=1)
      if " " in element.strip():
          # Something has gone wrong if there are still internal spaces
          raise ValueError(f"Cannot parse ion {ion}")
      # Convert stage to arabic numerals
      stage = (
          stage.replace("IV", "4")
          .replace("III", "3")
          .replace("II", "2")
          .replace("I", "1")
      )
      return rf"{prefix}\ion{{{element}}}{{{stage}}}{suffix}"


  def extra_e_wave(row, zones):
      """Extra uncertainty in wavelength, based on Fig A2 of paper"""
      max_flux = np.nanmax([row[f"F({zone})"] for zone in zones])
      if max_flux > 10.0:
          return row["wave"] * 1.0 / 3e5
      elif max_flux > 1.0:
          return row["wave"] * 3.0 / 3e5
      elif max_flux > 0.1:
          return row["wave"] * 5.0 / 3e5
      else:
          return row["wave"] * 15.0 / 3e5


  def extract_blends(notes):
      """Extract blend information from notes"""
      blends = []
      for text in notes:
          if not text:
              continue
          if "plus" in text:
              blends += re.split("plus|and maybe|,|and", text)
          elif text.startswith("Blend with"):
              blends += text.replace("Blend with", "").split(",")
          elif text.startswith("Doublet with components"):
              blends += [text.split(",")[-1]]
          else:
              blends += [text]
      return blends


  df = pd.read_csv("known-lines-with-h2-final-table.csv")
  table = []
  zones = ["0", "I", "II", "III", "IV", "MYSO"]
  skip_these_blends = (
      # New ones from the H2 lines
      "6270",
      "6529",
      "7803",
      "7837",
      "8694",
      "8304",
      "8680",
      # Original ones from the atomic list - Special case for [Cl II] and
      # He I lines that are sort of blended, but both have flux
      # measurements And also He I triplet
      "8578",
      "8582",
      "8776",
      "8045",
      "8216",
      "8230",
      "8306",
  )
  for _, row in df.iterrows():
      ion, wavrest = row["ID"].rsplit(maxsplit=1)
      print(ion, wavrest)
      # H_2 lines need the A stripping off
      wavrest = wavrest.rstrip("A")
      # Special case for [N I], where I unwisely put the mean doublet wavelength in the spreadsheet
      wavrest = wavrest.replace("5199.00", "5197.98")
      # For H_2 lines we look for extra blend info
      is_h2blend = False
      if ion.startswith("H_2"):
          h2_index = int(row["H2_index"])
          h2datafile = list(Path.cwd().glob(f"{h2_index:04d}*.yaml"))[0]
          h2data = yaml.safe_load(h2datafile.read_text())
          is_h2blend = h2data["Notes"] and h2data["Notes"].lower().startswith("blend")

      if (row["blend"] or is_h2blend) and not wavrest.startswith(skip_these_blends):
          blend_label = LETTERS.pop()
      else:
          blend_label = ""
      table.append(
          {
              r"\lambda(\text{obs})": format_pair(
                  row["wave"], np.hypot(row["e_wave"], extra_e_wave(row, zones))
              ),
              "Species": format_ion(ion.strip()),
              r"\lambda(\text{rest})": format_float(wavrest.strip("+?"), dp=2),
              r"Wav sort": format_float(wavrest.strip("+?"), dp=2),
              "Blend": blend_label,
              ,**{
                  rf"\text{{Zone {zone}}}": format_pair(
                      row[f"F({zone})"], row[f"E({zone})"] + 0.005, dp=2
                  )
                  for zone in zones
              },
          }
      )

      # Add extra entries for all the blends with this line
      #
      if blend_label:
          datafile = list(ORIG_DATA_PATH.glob(f"{row['Index']:04d}*.yaml"))[0]
          data = yaml.safe_load(datafile.read_text())
          try:
              notes = data["Notes"]["ID"]
              blends = extract_blends(notes)
          except KeyError:
              # Guard against missing Notes data
              blends = []

          # Also look for H_2 blends
          if is_h2blend:
              # Could be previous or next in sequence of lab wavelengths
              for j in h2_index - 1, h2_index + 1:
                  bdatafiles = list(Path.cwd().glob(f"{j:04d}*.yaml"))
                  if len(bdatafiles) == 1:
                      bdata = yaml.safe_load(bdatafiles[0].read_text())
                      # Check that this line has been tagged as a blend
                      # of the main line that we are looking at, and
                      # also that the predicted intensity is at least a
                      # certain fraction of the main line
                      if (
                          bdata.get("blend_index") == h2_index
                          and bdata["I_Inorm"]
                          > MINIMUM_H2_BLEND_STRENGTH * h2data["I_Inorm"]
                      ):
                          blends.append(
                              f"H_2 {bdata['H2_line']} {bdata['wl_lab'].strip('A')}"
                          )

          print(blend_label, blends)
          if len(blends) == 0:
              # No blends found, so we must hand back the label we took
              LETTERS.append(blend_label)
              print("Returning label", blend_label, "to the pool")
              # And also remove label from the main entry
              table[-1]["Blend"] = ""
              # And no point carrying on
              continue
          # What to assume when bare wavelength is given
          implicit_ion = ion
          for blend in blends:
              if not blend.strip():
                  # Skip case of empty or blank string
                  continue
              try:
                  _ion, _wavrest = blend.strip().rsplit(maxsplit=1)
              except ValueError:
                  # A bare wavelength is assumed to be the last ion that was mentioned
                  _ion = implicit_ion
                  _wavrest = blend
              if _wavrest.lower() == "sky":
                  _ion, _wavrest = _ion.rsplit(maxsplit=1)
              _wavrest = _wavrest.strip("+?,").strip()
              if _wavrest.startswith(skip_these_blends):
                  # Another chance to bail out
                  print("Skipping", _ion, _wavrest)
                  continue
              try:
                  ion_string = format_ion(_ion.strip())
                  wavrest_string = format_float(_wavrest, dp=2)
                  if ion_string.startswith("Sky"):
                      # Make use of the lambda(obs) column to put rest
                      # wavelength of sky line in frame of the nebula
                      _wavobs = float(_wavrest) / (1.0 + VSYS / 3.0e5)
                      # And use this wavelength for sorting
                      wavsort = format_float(_wavobs, dp=2)
                      wavobs_string = r"\mathit{" + wavsort + "}"
                  else:
                      # Other lines just use the lab rest wavelength
                      wavsort = wavrest_string
                      wavobs_string = ""
              except:
                  print("Failed to format blend: ion =", _ion, "wav =", _wavrest)
                  continue
              # Since this was a successfully identified blend, update
              # the ion that we use in the case that following blends have
              # bare wavelength
              implicit_ion = _ion
              table.append(
                  {
                      "Wav sort": wavsort,
                      r"\lambda(\text{obs})": wavobs_string,
                      "Species": ion_string,
                      r"\lambda(\text{rest})": wavrest_string,
                      "Blend": blend_label,
                      ,**{rf"\text{{Zone {zone}}}": "" for zone in zones},
                  }
              )

  dff = pd.DataFrame(table).sort_values(by="Wav sort").drop(columns=["Wav sort"])

  s = dff.style.hide()


  with open("known-lines-with-h2-final-table.tex", "w") as f:
      f.write(
          s.to_latex(
              hrules=True,
              siunitx=False,
              environment="longtable",
              column_format="RrRr " + "R" * len(zones),
          )
      )
#+end_src

#+begin_src sh :dir ../data/n346-h2-lines :results output verbatim
  python ../../scripts/convert-table-known-lines-with-h2-latex.py
#+end_src

#+RESULTS:
#+begin_example
[Fe III] 4607.12+
a ['', ' N II 4607.16']
O II 4641.81+
b ['', ' 4638.86 ', ' N II 4643.06 ', ' N III 4640.64']
O II 4649.13+
c ['', ' 4650.84']
[Fe III] 4658.10
He II 4685.68
[Fe III] 4701.62
[Ar IV] 4711.37+
d [' He I 4713.14']
[Fe III] 4734.00
[Ar IV] 4740.17
[Fe III] 4754.81
[Fe III] 4769.53
[Fe II] 4814.534
H I 4861.32
[Fe III] 4881.073
He I 4921.93
[Fe III] 4930.64
[O III] 4958.91
[Fe III] 4987.20+
e ['', ' 4985.90']
[O III] 5006.84
He I 5015.68
Si II 5041.03
He I 5047.74
Si II 5055.98
O I 5146.61
[Fe II] 5158.81
[Ar  III] 5191.82
[N I] 5199.00+
f [' 5200.26']
[Fe II] 5261.61
[Fe III] 5270.40+
g [' [Fe II] 5273.38']
[Fe II] 5333.646
[Fe II] 5376.452
[Cl III] 5517.71
[Cl III]] 5537.88
Si III 5739.73
[N II] 5755.08
Ni II 5867.99
He I 5875.62
Si II 5978.93
H_2 7-2 S(7) 6029.57A
H_2 7-2 S(1) 6037.46A
O I 6046.23
H_2 7-2 S(0) 6083.08A
[K IV] 6101.79
H_2 4-0 S(5) 6221.63A
Fe II 6248.91
H_2 12-5 S(1) 6261.73A
H_2 4-0 S(3) 6270.24A
[O I] 6300.30
[S III] 6312.06
Fe II 6317.99
Si II 6347.11
[O I] 6363.78
Si II 6371.36
Fe II 6383.73+
h ['', ' Fe II 6385.46']
H_2 4-0 S(12) 6434.04A
i ['H_2 4-0 S(0) 6434.99']
H_2 8-3 S(3) 6450.83A
Fe II 6455.8427
H_2 8-3 S(5) 6459.07A
H_2 8-3 S(2) 6469.13A
H_2 8-3 S(6) 6486.30A
Fe II 6493.04+
j ['', ' Fe II 6491.2544']
H_2 8-3 S(1) 6502.09A
Fe II 6517.03
H_2 8-3 S(7) 6529.62A
[N II] 6548.05
H I 6562.79
[N II] 6583.45
H_2 4-0 Q(3) 6615.09A
H_2 5-1 S(5) 6629.04A
k ['', ' OH 6634 sky']
H_2 5-1 S(7) 6636.69A
H_2 5-1 S(4) 6645.58A
H_2 8-3 Q(1) 6656.12A
[Ni II] 6666.80
He I 6678.15
H_2 5-1 S(9) 6699.11A
[S II] 6716.44
[S II] 6730.816
H_2 5-1 S(1) 6776.75A
[K IV] 6795.1
H_2 5-1 S(0) 6847.81A
H_2 5-1 Q(1) 6987.18A
O I 7001.92
H_2 5-1 Q(2) 7009.46A
l ['H_2 9-4 S(3) 7011.24']
H_2 9-4 S(4) 7015.36A
H_2 9-4 S(2) 7025.14A
H_2 9-4 S(5) 7038.03A
H_2 5-1 Q(3) 7042.98A
H_2 9-4 S(1) 7056.69A
He I 7065.28
H_2 9-4 S(6) 7080.02A
H_2 6-2 S(5) 7091.93A
H_2 6-2 S(4) 7105.43A
m ['H_2 9-4 S(0) 7105.68']
H_2 6-2 S(7) 7111.45A
[Ar III] 7135.78
H_2 5-1 Q(5) 7144.42A
n ['H_2 5-1 O(2) 7143.90', 'H_2 6-2 S(8) 7144.85']
[Fe II] 7155.14
He I 7160.13
[Ar IV] 7170.5
H_2 6-2 S(2) 7178.58A
H_2 11-5 O(3) 7186.19A
H_2 6-2 S(9) 7194.43A
H_2 13-6 S(2) 7199.27A
H_2 9-4 Q(1) 7221.48A
H_2 6-2 S(1) 7238.21A
o [' [Ar IV] 7237.4', 'Also, several OH sky lines but they are weak and probably do not interfere']
Failed to format blend: ion = Also, several OH sky lines but they are weak and probably do not wav = interfere
O I 7254.15+
p [' 7254.45', ' 7254.53', 'Wavelength followed by + indicates blend. Secondary components should be listed in attached note']
Failed to format blend: ion = Wavelength followed by + indicates blend. Secondary components should be listed in attached wav = note
[Ar IV] 7262.7+
q [' [Cl IV] 7261.4']
He I 7281.35
H_2 5-1 Q(7) 7293.34A
H_2 13-6 Q(2) 7304.73A
[O II] 7319.99+
r ['', ' 7318.39']
[O II] 7330.73+
s ['', ' 7329.66 ', ' ', ' [Ar IV] 7331.4']
[Ni II] 7377.83
[Ni II] 7411.61
H_2 4-0 O(7) 7426.27A
N I 7442.30
[Fe II] 7452.54?
H_2 6-2 Q(1) 7462.84A
N I 7468.31+
t ['', ' OH 7473.7 sky']
H_2 6-2 Q(2) 7488.21A
He I 7499.85
Fe II 7513.1762
H_2 6-2 Q(3) 7526.43A
u [' [Cl IV] 7530.8']
[Cl IV] 7530.8
H_2 7-3 S(5) 7628.56A
H_2 7-3 S(4) 7636.91A
v ['H_2 7-3 S(6) 7638.24']
H_2 7-3 S(3) 7663.09A
w []
Returning label w to the pool
H_2 7-3 S(2) 7706.96A
w ['', ' OH 7712 sky', 'H_2 10-5 S(3) 7707.12']
H_2 12-6 S(2) 7721.51A
x ['', ' OH 7726 sky', 'H_2 6-2 Q(6) 7720.70']
H_2 10-5 S(4) 7724.23A
H_2 10-5 S(1) 7740.69A
[Ar III] 7751.10
H_2 7-3 S(1) 7768.49A
H_2 3-0 S(7) 7782.22A
H_2 10-5 S(0) 7790.25A
y ['', ' OH 7794 sky', 'H_2 3-0 S(9) 7790.99']
H_2 4-0 O(9) 7806.24A
z []
Returning label z to the pool
He I 7816.13+
z ['', ' OH 7822 sky']
H_2 3-0 S(5) 7837.75A
H_2 7-3 S(0) 7847.68A
aa ['', ' OH 7853 sky']
H_2 3-0 S(11) 7862.67A
ab ['', ' OH 7868 sky']
H_2 3-0 S(4) 7890.29A
H_2 11-5 Q(9) 7917.04A
ac ['', ' OH 7921 sky']
H_2 3-0 S(3) 7959.75A
ad ['', ' OH 7964.65']
[Fe II] 7997.03+
ae ['', ' [Fe II] 7999.47 ', ' [Cr II] 8000.08']
H_2 7-3 Q(1) 8008.96A
af ['', ' OH 8014.1']
H_2 7-3 Q(2) 8038.44A
[Cl IV] 8045.62+
H_2 10-5 O(2) 8068.77A
ag []
Returning label ag to the pool
H_2 7-3 Q(3) 8082.91A
Ca I] 8125.31
H_2 3-0 S(1) 8150.65A
N I 8188.012
H_2 7-3 O(2) 8192.31A
N I 8200.357
H_2 10-5 S(9) 8206.90A
N I 8210.715
N I 8216.34+
N I 8223.14+
ag ['', ' O I 8221.824  ']
O I 8230.00+
He II 8236.78
N I 8242.39
H_2 8-4 S(5) 8266.55A
ah ['H_2 8-4 S(4) 8266.30']
H_2 3-0 S(0) 8272.65A
H_2 4-1 S(7) 8283.51A
ai ['', ' OH 8288.6 sky']
H_2 8-4 S(3) 8287.27A
H_2 4-1 S(6) 8300.03A
aj ['', ' H I 8298.83']
H_2 4-1 S(9) 8304.07A
H I 8306.11+
H I 8314.26
H I 8323.42
H_2 8-4 S(2) 8329.17A
H_2 4-1 S(5) 8334.66A
ak ['', ' H I 8333.782']
H I 8345.55
H I 8359.00+
al ['', ' He I 8361.73']
H I 8374.48
H_2 4-1 S(4) 8387.65A
H_2 8-4 S(8) 8400.71A
H I 8413.32+
am ['', ' OH 8415.2 sky']
H I 8437.96
O I 8446.48
H_2 4-1 S(3) 8459.29A
an ['', ' OH 8465.2', ' ', ' Ca I] 8459.50 perhaps']
Failed to format blend: ion = Ca I] 8459.50 wav = perhaps
H I 8467.26
H_2 8-4 S(0) 8475.17A
H_2 3-0 Q(1) 8497.45A
H I 8502.49
He I 8518.04
H_2 3-0 Q(2) 8522.57A
He I 8528.95
H I 8545.38+
ao ['', ' OH 8548.7 sky']
H_2 4-1 S(2) 8549.88A
H_2 4-1 S(13) 8560.02A
ap ['H_2 3-0 Q(3) 8560.35']
[Cl II] 8578.69+
He I 8582.61+
H I 8598.39
H_2 11-6 S(3) 8610.91A
[Fe II] 8616.95
H_2 11-6 S(1) 8620.81A
N I 8629.24
H_2 8-4 Q(1) 8650.16A
aq ['', ' O_2 8651.28']
H_2 4-1 S(1) 8659.72A
H I 8665.02
H_2 3-0 Q(5) 8674.35A
ar ['', ' O_2 8676.1']
N I 8680.282
H_2 8-4 Q(2) 8685.29A
as ['', ' N I 8683.40', ' 8686.15', ' 8680.28']
Skipping N I 8680.28
H_2 14-7 Q(2) 8692.04A
at ['', ' neutral UIL', 'H_2 7-3 Q(9) 8691.59']
Failed to format blend: ion = neutral wav = UIL
N I 8703.247
N I 8711.703
N I 8718.837
[C I] 8727.13
He I 8733.43
H_2 8-4 Q(3) 8738.38A
H I 8750.47
He I 8776.71+
H_2 4-1 S(0) 8789.12A
H_2 8-4 Q(4) 8809.90A
au ['H_2 11-6 Q(1) 8809.76']
H_2 3-0 Q(7) 8840.89A
H_2 5-2 S(7) 8850.66A
H I 8862.79
H_2 5-2 S(9) 8888.85A
H_2 5-2 S(5) 8893.81A
H_2 5-2 S(4) 8946.15A
H I 9014.91
H_2 5-2 S(3) 9019.30A
H_2 4-1 Q(1) 9029.26A
H_2 9-5 S(4) 9034.88A
H_2 9-5 S(5) 9049.69A
av ['H_2 11-6 Q(4) 9049.54']
H_2 4-1 Q(2) 9057.20A
He I 9063.29
[S III] 9068.90
H_2 9-5 S(2) 9083.40A
H_2 4-1 Q(3) 9099.25A
H_2 5-2 S(2) 9113.54A
[Cl II] 9123.60
H_2 9-5 S(1) 9145.66A
H_2 4-1 Q(4) 9155.56A
H_2 9-5 S(7) 9162.58A
Ca I] 9204.09
He I 9210.28
Fe I] 9218.47
H I 9229.01
Ca I] 9244.31
H_2 9-5 S(8) 9264.11A
H_2 4-1 O(2) 9297.59A
aw []
Returning label aw to the pool
#+end_example

*** Calculate the reddening from H2 lines that share an upper level
- We want top select the best pairs for doing this, otherwise we will be swamped by noise and blends
- So we want the following:
  1. Large wavelength separation between the lines (e.g., 6600 to 9000)
  2. Neither line is affected by an obvious blend
  3. S/N of at least 3 for both lines. This will generally be determined by the weaker line, which is usually the shorter wavelength
- We may want to relax #1 actually, so can demonstrate that the measurements are consistent with the theoretical A values when the wavelength difference is negligible.
- Then what we can do is to assume that the extinction is proportional to 1 / lambda
  - So we calculate the ratio of ratios: [I(long) / I(short)] divided by [g A h nu (long) / g A h nu (short)]
- Question is: do we just put the lines in by hand, or do we automate it?

**** Make a list of pairs of lines that share an upper level
- We want to combine the two tables:
  1. ~h2-line-ids.csv~ that has rovibrational levels and the transition probabilities
  2. ~known-lines-with-h2-final-table.csv~ that has the reddening-corrected fluxes for the lines
     
#+begin_src python :eval no :tangle ../scripts/h2-find-reddening-pairs.py
  import numpy as np
  import yaml
  from pathlib import Path
  import pandas as pd
  import typer
  import sys
  COLS = ["Index", "H2_line",  "Vhi",  "Jhi",  "Vlo",  "Jlo", "wl_mic", "wl_lab", "I_Inorm",  "Excit_hi_K", "g_u_h_nu_Aul", 
          "F(0)", "E(0)", "F(MYSO)", "E(MYSO)"]

  def main(
              data_dir: str="n346-h2-lines",
              min_snr: float=2.0,
  ):
        df1 = pd.read_csv(Path(data_dir) / "known-lines-with-h2-final-table.csv")
        df1 = (df1       
               # removing low s/n lines
               [df1["F(0)"] > min_snr * df1["E(0)"]]
               # removing blends
               [~df1["Notes"].str.contains("blend", na=False)]
               #[~df1["blend"]]
               # And other dubious lines
               [~df1["Notes"].str.contains("elam = 2 sig", na=False)]
               )
        df2 = pd.read_csv(Path(data_dir) / "h2-line-ids.csv")
        # Merge the two tables on the name of the H2 lines
        grouped = (df2.merge(df1, how="inner", on="H2_index")[COLS]
                   # sorted by energy, then wavelength
                   .sort_values(by=["Excit_hi_K", "wl_mic"])
                   .groupby("Excit_hi_K")
                   )
        # select groups of two or more lines with the same upper level and save to csv
        grouped.filter(lambda x: len(x) > 1).to_csv(Path(data_dir) / "h2-reddening-lines-table.csv")

        # now reorganise the date with one row per pair
        red_pairs = []
        for name, group in grouped:
              if len(group) > 1:
                    print(name)
                    group["cloudy_theo"] = 1e-16 * 100 * group["I_Inorm"] / group["g_u_h_nu_Aul"]
                    group["obs_theo"] = 1e-16 * group["F(0)"] / group["g_u_h_nu_Aul"]
                    group["s_n"] = group["F(0)"] / group["E(0)"]
                    group["wav_ratio"] = group.iloc[-1]["wl_mic"] / group["wl_mic"]

                    group = group.drop(columns=["Excit_hi_K", "g_u_h_nu_Aul", "I_Inorm"])
                    print(group)
                    # take ratio of the shortest wave with each longer wave in turn
                    short = group.iloc[0, :]
                    for _, long in group.iloc[1:, :].iterrows():
                          if short.H2_line == long.H2_line:
                                continue
                          red_pairs.append(
                                dict(
                                      lines = f"{short.H2_line} / {long.H2_line}",
                                      waves = f"{short.wl_lab.strip('A')} / {long.wl_lab.strip('A')}",
                                      obs_theo_ratio = short.obs_theo / long.obs_theo,
                                      wav_ratio = long.wl_mic / short.wl_mic,
                                      Texcit = name,
                                      long_wav = long.wl_mic,
                                      rel_error = np.hypot(1.0 / short.s_n, 1.0 / long.s_n),
                                      bright_product = 100 * short["F(0)"] * long["F(0)"],
                                )
                          )
        # Save list of pairs
        df0 = pd.DataFrame(red_pairs).sort_values("wav_ratio")
        df0.to_csv(Path(data_dir) / "h2-reddening-pairs-table.csv")
        print(df0)


  if __name__ == "__main__":
      typer.run(main)

#+end_src

#+begin_src sh :dir ../data :results output verbatim
  COLUMNS=1000 python ../scripts/h2-find-reddening-pairs.py --min-snr 4
#+end_src

#+RESULTS:
#+begin_example
17387.183
    Index   H2_line  Vhi  Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)      E(0)   F(MYSO)   E(MYSO)  cloudy_theo   obs_theo        s_n  wav_ratio
46   2942  3-0 S(0)  3.0  2.0  0.0  0.0  0.827265  8272.65A  0.166051  0.004725  0.032877  0.016393     2.992281  64.087556  35.139352    1.03021
59   3142  3-0 Q(2)  3.0  2.0  0.0  2.0  0.852257  8522.57A  0.109301  0.004602  0.044541  0.003113     2.992191  50.207381  23.750375    1.00000
22352.468
    Index   H2_line  Vhi  Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)      E(0)   F(MYSO)   E(MYSO)  cloudy_theo   obs_theo        s_n  wav_ratio
66   3355  4-1 S(0)  4.0  2.0  1.0  0.0  0.878912  8789.12A  0.193339  0.008964  0.061324  0.003418     1.660517  23.013863  21.567475   1.030502
73   3570  4-1 Q(2)  4.0  2.0  1.0  2.0  0.905720  9057.20A  0.200774  0.006608       NaN       NaN     1.660106  27.253189  30.381933   1.000000
22758.987
    Index   H2_line  Vhi  Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)      E(0)   F(MYSO)   E(MYSO)  cloudy_theo  obs_theo        s_n  wav_ratio
63   3252  4-1 S(1)  4.0  3.0  1.0  1.0  0.865972  8659.72A  0.380180  0.027189  0.042248  0.011814     0.492886  6.439371  13.982899   1.050756
75   3603  4-1 Q(3)  4.0  3.0  1.0  3.0  0.909925  9099.25A  0.207403  0.017341  0.195240  0.143527     0.492734  7.176582  11.959967   1.000000
23294.809
    Index   H2_line  Vhi  Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)      E(0)   F(MYSO)   E(MYSO)  cloudy_theo  obs_theo        s_n  wav_ratio
60   3164  4-1 S(2)  4.0  4.0  1.0  2.0  0.854988  8549.88A  0.211016  0.014921  0.037104  0.002809     0.676084  6.022148  14.141855   1.070842
78   3649  4-1 Q(4)  4.0  4.0  1.0  4.0  0.915556  9155.56A  0.065545  0.012537       NaN       NaN     0.676368  5.434950   5.227997   1.000000
23954.871
    Index   H2_line  Vhi  Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)      E(0)   F(MYSO)   E(MYSO)  cloudy_theo   obs_theo       s_n  wav_ratio
29   2263  4-0 O(7)  4.0  5.0  0.0  7.0  0.742627  7426.27A  0.017396  0.001974  0.070335  0.012076     0.190403  24.408822  8.812503   1.139103
56   3091  4-1 S(3)  4.0  5.0  1.0  3.0  0.845929  8459.29A  0.468973  0.065199  0.207789  0.024897     0.190319   2.873611  7.192923   1.000000
25622.762
    Index   H2_line  Vhi  Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)      E(0)   F(MYSO)   E(MYSO)  cloudy_theo  obs_theo        s_n  wav_ratio
2    1300  4-0 S(5)  4.0  7.0  0.0  5.0  0.622163  6221.63A  0.037499  0.002365  0.023332  0.002593     0.077661  1.064403  15.857241   1.339627
53   2991  4-1 S(5)  4.0  7.0  1.0  5.0  0.833466  8334.66A  0.517265  0.062334  0.355479  0.028211     0.077669  1.693728   8.298325   1.000000
27374.175
    Index   H2_line  Vhi  Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)      E(0)   F(MYSO)   E(MYSO)  cloudy_theo  obs_theo        s_n  wav_ratio
12   1744  5-1 S(1)  5.0  3.0  1.0  1.0  0.677675  6776.75A  0.055403  0.005957  0.025083  0.002450     0.318344  2.997973   9.300593   1.039286
18   1958  5-1 Q(3)  5.0  3.0  1.0  3.0  0.704298  7042.98A  0.036400  0.001804  0.020118  0.003293     0.318343  5.606026  20.175573   1.000000
29228.502
    Index   H2_line  Vhi  Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)      E(0)   F(MYSO)   E(MYSO)  cloudy_theo  obs_theo        s_n  wav_ratio
9    1640  5-1 S(4)  5.0  6.0  1.0  4.0  0.664558  6645.58A  0.035754  0.002236  0.020364  0.000783     0.132817  1.179229  15.992958    1.34618
70   3481  5-2 S(4)  5.0  6.0  2.0  4.0  0.894615  8946.15A  0.152794  0.028027  0.068645  0.019524     0.132866  1.070736   5.451674    1.00000
30138.666
    Index   H2_line  Vhi   Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)      E(0)   F(MYSO)   E(MYSO)  cloudy_theo  obs_theo        s_n  wav_ratio
50   2967  4-1 S(9)  4.0  11.0  1.0  9.0  0.830407  8304.07A  0.168636  0.040220  0.052620  0.013895     0.028577  0.300438   4.192827        1.0
51   2969  4-1 S(9)  4.0  11.0  1.0  9.0  0.830407  8304.07A  0.129072  0.010169  0.158844  0.061508     0.028577  0.229951  12.692439        1.0
31661.077
    Index   H2_line  Vhi  Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)      E(0)   F(MYSO)   E(MYSO)  cloudy_theo  obs_theo         s_n  wav_ratio
28   2114  6-2 S(1)  6.0  3.0  2.0  1.0  0.723821  7238.21A  0.066132  0.016501  0.019544  0.016033     0.206537  1.527656    4.007658   1.039819
32   2345  6-2 Q(3)  6.0  3.0  2.0  3.0  0.752643  7526.43A  0.067217  0.000223  0.030750  0.000823     0.206543  4.034645  301.613333   1.000000
32014.382
    Index   H2_line  Vhi  Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)      E(0)   F(MYSO)   E(MYSO)  cloudy_theo  obs_theo        s_n  wav_ratio
8    1632  5-1 S(7)  5.0  9.0  1.0  7.0  0.663669  6636.69A  0.059644  0.007285  0.157934  0.062761     0.023173  0.286748   8.187266   1.333594
67   3405  5-2 S(7)  5.0  9.0  2.0  7.0  0.885066  8850.66A  0.229371  0.015721  0.089079  0.009766     0.023177  0.289390  14.589635   1.000000
34288.459
    Index   H2_line  Vhi   Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)      E(0)   F(MYSO)   E(MYSO)  cloudy_theo  obs_theo        s_n  wav_ratio
11   1682  5-1 S(9)  5.0  11.0  1.0  9.0  0.669911  6699.11A  0.027720  0.002110  0.011564  0.002283     0.017956  0.098195  13.134514    1.32687
68   3435  5-2 S(9)  5.0  11.0  2.0  9.0  0.888885  8888.85A  0.089201  0.011274  0.021779  0.003140     0.017963  0.094533   7.912289    1.00000
35613.272
    Index   H2_line  Vhi  Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)      E(0)   F(MYSO)   E(MYSO)  cloudy_theo  obs_theo        s_n  wav_ratio
1    1153  7-2 S(1)  7.0  3.0  2.0  1.0  0.603746  6037.46A  0.035879  0.003406  0.022362  0.004802     0.142849  2.165282  10.532945   1.338793
35   2538  7-3 S(1)  7.0  3.0  3.0  1.0  0.776849  7768.49A  0.113539  0.007952  0.023261  0.007891     0.142821  1.447828  14.277337   1.040474
42   2790  7-3 Q(3)  7.0  3.0  3.0  3.0  0.808291  8082.91A  0.059422  0.002252  0.037058  0.003168     0.142836  1.800129  26.380769   1.000000
38707.583
    Index   H2_line  Vhi  Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)     E(0)   F(MYSO)   E(MYSO)  cloudy_theo  obs_theo        s_n  wav_ratio
10   1648  8-3 Q(1)  8.0  1.0  3.0  1.0  0.665612  6656.12A  0.030264  0.00241  0.008542  0.001906     0.206333  4.416236  12.557557    1.29958
62   3244  8-4 Q(1)  8.0  1.0  4.0  1.0  0.865016  8650.16A  0.182262  0.02522  0.054680  0.007434     0.206361  5.129810   7.226752    1.00000
38913.587
    Index   H2_line  Vhi  Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)      E(0)   F(MYSO)   E(MYSO)  cloudy_theo  obs_theo        s_n  wav_ratio
57   3104  8-4 S(0)  8.0  2.0  4.0  0.0  0.847517  8475.17A  0.115172  0.010556  0.025858  0.003017     0.365223  6.835105  10.910397   1.024793
64   3272  8-4 Q(2)  8.0  2.0  4.0  2.0  0.868529  8685.29A  0.096575  0.007186  0.079538  0.029306     0.365064  6.829891  13.439411   1.000000
39219.492
    Index   H2_line  Vhi  Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)      E(0)   F(MYSO)   E(MYSO)  cloudy_theo  obs_theo        s_n  wav_ratio
6    1524  8-3 S(1)  8.0  3.0  3.0  1.0  0.650209  6502.09A  0.045548  0.002180  0.013620  0.001162     0.101888  1.343982  20.894083   1.343935
65   3315  8-4 Q(3)  8.0  3.0  4.0  3.0  0.873838  8738.38A  0.064774  0.004399  0.025118  0.002079     0.101870  1.164784  14.725264   1.000000
42462.426
    Index   H2_line  Vhi  Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)      E(0)   F(MYSO)   E(MYSO)  cloudy_theo  obs_theo       s_n  wav_ratio
19   1969  9-4 S(1)  9.0  3.0  4.0  1.0  0.705669  7056.69A  0.079988  0.018529  0.059081  0.010433     0.073271  1.382916  4.316896   1.296027
77   3640  9-5 S(1)  9.0  3.0  5.0  1.0  0.914566  9145.66A  0.124354  0.016139  0.062477  0.030923     0.073264  0.757333  7.705187   1.000000
42827.236
    Index   H2_line  Vhi  Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)      E(0)   F(MYSO)   E(MYSO)  cloudy_theo  obs_theo       s_n  wav_ratio
16   1944  9-4 S(2)  9.0  4.0  4.0  2.0  0.702514  7025.14A  0.030010  0.004199  0.054419  0.024145     0.100378  0.810215  7.146297   1.292985
74   3591  9-5 S(2)  9.0  4.0  5.0  2.0  0.908340  9083.40A  0.061664  0.010837  0.054953  0.052135     0.100387  0.645427  5.690260   1.000000
43798.108
    Index   H2_line  Vhi  Jhi  Vlo  Jlo    wl_mic    wl_lab      F(0)      E(0)   F(MYSO)   E(MYSO)  cloudy_theo  obs_theo       s_n  wav_ratio
15   1936  9-4 S(4)  9.0  6.0  4.0  4.0  0.701536  7015.36A  0.019512  0.002142  0.027242  0.005749     0.032119  0.215430  9.110236   1.287871
72   3552  9-5 S(4)  9.0  6.0  5.0  4.0  0.903488  9034.88A  0.032524  0.005228  0.035862  0.019386     0.032131  0.163111  6.220834   1.000000
                  lines              waves  obs_theo_ratio  wav_ratio     Texcit  long_wav  rel_error  bright_product
14  8-4 S(0) / 8-4 Q(2)  8475.17 / 8685.29        1.000763   1.024793  38913.587  0.868529   0.118056        1.112265
0   3-0 S(0) / 3-0 Q(2)  8272.65 / 8522.57        1.276457   1.030210  17387.183  0.852257   0.050820        1.814960
1   4-1 S(0) / 4-1 Q(2)  8789.12 / 9057.20        0.844447   1.030502  22352.468  0.905720   0.056861        3.881759
6   5-1 S(1) / 5-1 Q(3)  6776.75 / 7042.98        0.534777   1.039286  27374.175  0.704298   0.118394        0.201665
8   6-2 S(1) / 6-2 Q(3)  7238.21 / 7526.43        0.378634   1.039819  31661.077  0.752643   0.249544        0.444522
2   4-1 S(1) / 4-1 Q(3)  8659.72 / 9099.25        0.897275   1.050756  22758.987  0.909925   0.110025        7.885065
3   4-1 S(2) / 4-1 Q(4)  8549.88 / 9155.56        1.108041   1.070842  23294.809  0.915556   0.203930        1.383115
4   4-0 O(7) / 4-1 S(3)  7426.27 / 8459.29        8.494129   1.139103  23954.871  0.845929   0.179457        0.815834
11  7-2 S(1) / 7-3 S(1)  6037.46 / 7768.49        1.495538   1.286715  35613.272  0.776849   0.117980        0.407362
18  9-4 S(4) / 9-5 S(4)  7015.36 / 9034.88        1.320763   1.287871  43798.108  0.903488   0.194652        0.063460
17  9-4 S(2) / 9-5 S(2)  7025.14 / 9083.40        1.255317   1.292985  42827.236  0.908340   0.224645        0.185056
16  9-4 S(1) / 9-5 S(1)  7056.69 / 9145.66        1.826035   1.296027  42462.426  0.914566   0.265526        0.994682
13  8-3 Q(1) / 8-4 Q(1)  6656.12 / 8650.16        0.860897   1.299580  38707.583  0.865016   0.159653        0.551607
10  5-1 S(9) / 5-2 S(9)  6699.11 / 8888.85        1.038736   1.326870  34288.459  0.888885   0.147546        0.247269
9   5-1 S(7) / 5-2 S(7)  6636.69 / 8850.66        0.990869   1.333594  32014.382  0.885066   0.140058        1.368048
12  7-2 S(1) / 7-3 Q(3)  6037.46 / 8082.91        1.202848   1.338793  35613.272  0.808291   0.102228        0.213199
5   4-0 S(5) / 4-1 S(5)  6221.63 / 8334.66        0.628438   1.339627  25622.762  0.833466   0.136010        1.939686
15  8-3 S(1) / 8-4 Q(3)  6502.09 / 8738.38        1.153847   1.343935  39219.492  0.873838   0.083081        0.295028
7   5-1 S(4) / 5-2 S(4)  6645.58 / 8946.15        1.101325   1.346180  29228.502  0.894615   0.193794        0.546303
#+end_example

**** Plot the reddening ratios versus wavelength ratios
- Note that this gives pretty much a null result
- There is no obvious dependence of the reddening ratio on the wavelength ratio, suggesting that the reddening is smaller than the noise
#+begin_src python :eval no :tangle ../scripts/h2-reddening-plot.py
  import numpy as np
  import yaml
  from pathlib import Path
  import pandas as pd
  import typer
  import sys
  from matplotlib import pyplot as plt
  from astropy.stats import SigmaClip
  import matplotlib
  import seaborn as sns

  sns.set_context("talk")

  def main(
              data_path: Path=Path.cwd(),
              clip_sigma: float=2.0,
  ):
        df = pd.read_csv(data_path / "h2-reddening-pairs-table.csv")

        # Clip the outliers
        clip = SigmaClip(sigma=clip_sigma, maxiters=5)
        clipped = clip(df.obs_theo_ratio, masked=True)
        df = df.loc[~clipped.mask]

        fig, ax = plt.subplots()
        x = df.wav_ratio
        y = np.log(df.obs_theo_ratio)
        ey = np.log(1.0 + df.rel_error)
        size = 100 * df.bright_product
        ax.scatter(x, y, s=size)
        # errorbar does not accept array of lienwidths, so do one at a time
        for _x, _y, _ey in zip(x, y, ey):
              ax.errorbar(_x, _y, yerr=_ey, fmt="none", elinewidth=0.1/_ey)

        # Plot the theoretical curve
        xmin, xmax = 0.94, 1.39
        xpts = np.linspace(xmin, xmax)
        # Mean wavelength of long line in each pair, micron
        wav_2 = 0.87
        # Central wavelength of V and K bands 
        wav_V = 0.55
        wav_K = 2.0

        for Av, beta, linestyle in [[1.0, 1.4, "solid"], [1.0, 2.0, "dashed"], [0.3, 1.4, "dashdot"]]:
              tau_2 = Av / (1.0857 * (wav_2 / wav_V) ** beta)
              Ak = Av * (wav_V / wav_K) ** beta
              label = fr"$A_V = {Av:.1f}$, $\beta = {beta:.1f}$ ($A_K = {Ak:.2f}$)"
              ax.plot(xpts, tau_2 * (1.0 - xpts ** beta), label=label, linestyle=linestyle)
        ax.axhline(0.0, linewidth=0.5, color="k", linestyle="dotted")
        ax.axvline(1.0, linewidth=0.5, color="k", linestyle="dotted")
        ax.legend(loc="lower left", fontsize="x-small")
        ax.set(
              xlim=[xmin, xmax],
              ylim=[-0.49, 0.49],
              xlabel="Wavelength ratio: $\lambda_2$ / $\lambda_1$",
              ylabel=r"$\ln \left[\dfrac{(\mathrm{Observed\ /\ Predicted})_1}{(\mathrm{Observed\ /\ Predicted})_2}\right]$",
        )

        sns.despine()
        figfile = "h2-reddening.pdf"
        fig.savefig(figfile, bbox_inches="tight")
        print(figfile, end="")

  if __name__ == "__main__":
      typer.run(main)
#+end_src


#+begin_src sh :dir ../data/n346-h2-lines :results file
  python ../../scripts/h2-reddening-plot.py 
#+end_src

#+RESULTS:
[[file:/Users/will/Dropbox/muse-hii-regions/data/n346-h2-lines/h2-reddening.pdf]]

**** Theoretical expectation for reddening ratios
- assume an extinction curve of (1/lambda)^beta
- then log of ratio of obs/pred ratios is
  log(exp(-tau_1) / exp(-tau_2)) = tau_2 - tau_1
- which is tau_2 - tau_1 = tau_2 (1 - tau_1/tau_2) = tau_2 (1 - (lambda_2/lambda_1)^beta)
- This implies we should plot against (lambda_2/lambda_1 - 1), not log (but only if beta = 1)
- So we find tau_2 as log ratio / (lambda_2/lambda_1 - 1)
- [2024-01-16 Tue] Turning this back around so we can plot theoretical curve on figure
  - We now think that beta = 1.4 is appropriate for smc (see [[id:51B5A586-9F02-4D7C-84DC-A1538653B60E][below]])
  - This means that tau_2 = A_V/2.06
  - And log(ratio) = (A_V/2.06) (1 - (lambda_2/lambda_1)^1.4)
  - Add this to the graph

**** Statistics of the per-pair obs/pred ratios
- We can divide the pairs into two groups
  - df0 :: has wave ratio < 1.15
    - Used for checking reliability of observations
  - df1 :: has wave ratio >= 1.15
    - Used for calculating reddening in next section
- For the weights, we will use the product of the brightnesses, but capped at a certain value (I will use 1.5), which corresponds to a "good" observation of the two lines
#+begin_src python :eval no :tangle ../scripts/h2-reddening-statistics.py
  import numpy as np
  import yaml
  from pathlib import Path
  import pandas as pd
  from statsmodels.stats.weightstats import DescrStatsW
  from astropy.stats import SigmaClip
  import typer
  import sys
  from matplotlib import pyplot as plt
  import matplotlib

  import seaborn as sns


  def main(
              data_path: Path=Path.cwd(),
              min_wav_ratio: float=1.15,
              good_bright_product: float=1.5,
              clip_sigma: float=2.0,
  ):
        df = pd.read_csv(data_path / "h2-reddening-pairs-table.csv");
        # Weight is UNITY for pairs where bright_product is large
        # enough. These correspond to a "good" observation. Weight may
        # not exceed 1.0, but may be lower for less trustworthy pairs
        df["weights"] = np.minimum(1.0, df.bright_product / good_bright_product)
        df0 = df[df.wav_ratio < min_wav_ratio]
        df1 = df[df.wav_ratio >= min_wav_ratio]
        cols = ["wav_ratio", "obs_theo_ratio", "long_wav"]
        for df, descrip in [[df0, "CLOSE PAIRS"], [df1, "FAR PAIRS"]]:
              print("\n", descrip, "\n")
              print("Weighted statistics", "N = ", len(df))
              wstats = DescrStatsW(df[cols].to_numpy(), weights=df.weights)
              print("Column:\t", (cols))
              print("Mean:\t", np.round(wstats.mean, 2))
              print("Std:\t", np.round(wstats.std, 2))
              print("SEM:\t", np.round(wstats.std_mean, 2))
              print("N effective:\t", np.round(wstats.nobs, 2))
              print("CI 90:\n", np.round(wstats.tconfint_mean(alpha=0.1), 2))
              print("CI 68:\n", np.round(wstats.tconfint_mean(alpha=0.32), 2))
              print()

              print("Sigma-clipped statistics\n")
              clip = SigmaClip(sigma=clip_sigma, maxiters=5)
              clipped = clip(df.obs_theo_ratio, masked=True)
              dfc = df.loc[~clipped.mask]
              print(dfc.describe())
              print()

              print("Weighted AND sigma-clipped statistics", "N = ", len(dfc))
              wstats = DescrStatsW(dfc[cols].to_numpy(), weights=dfc.weights)
              print("Column:\t", (cols))
              print("Mean:\t", np.round(wstats.mean, 2))
              print("Std:\t", np.round(wstats.std, 2))
              print("SEM:\t", np.round(wstats.std_mean, 2))
              print("N effective:\t", np.round(wstats.nobs, 2))
              print("CI 90:\n", np.round(wstats.tconfint_mean(alpha=0.1), 2))
              print("CI 68:\n", np.round(wstats.tconfint_mean(alpha=0.32), 2))
              tstat, pvalue,  df = wstats.ttest_mean(value=0.8, alternative="larger")
              print("t-test of value < 0.8: p =", np.round(pvalue, 4))

              print()

  if __name__ == "__main__":
      typer.run(main)

#+end_src

#+begin_src sh :dir ../data/n346-h2-lines :results output verbatim
  COLUMNS=1000 python ../../scripts/h2-reddening-statistics.py --clip-sigma 2 --good-bright-product 1.0
#+end_src

#+RESULTS:
#+begin_example

 CLOSE PAIRS 

Weighted statistics N =  8
Column:	 ['wav_ratio', 'obs_theo_ratio', 'long_wav']
Mean:	 [1.05 1.91 0.87]
Std:	 [0.04 2.51 0.05]
SEM:	 [0.02 1.08 0.02]
N effective:	 6.46
CI 90:
 [[ 1.02 -0.22  0.83]
 [ 1.08  4.04  0.91]]
CI 68:
 [[1.04 0.73 0.85]
 [1.07 3.08 0.89]]

Sigma-clipped statistics

       Unnamed: 0  obs_theo_ratio  wav_ratio        Texcit  long_wav  rel_error  bright_product   weights
count    7.000000        7.000000   7.000000      7.000000  7.000000   7.000000        7.000000  7.000000
mean     4.857143        0.862914   1.040887  26248.898000  0.844133   0.129662        2.389050  0.806598
std      4.913538        0.314598   0.015702   7136.415503  0.083475   0.073088        2.707147  0.337655
min      0.000000        0.378634   1.024793  17387.183000  0.704298   0.050820        0.201665  0.201665
25%      1.500000        0.689612   1.030356  22555.727500  0.802450   0.083443        0.778394  0.722261
50%      3.000000        0.897275   1.039286  23294.809000  0.868529   0.118056        1.383115  1.000000
75%      7.000000        1.054402   1.045288  29517.626000  0.907823   0.161162        2.848359  1.000000
max     14.000000        1.276457   1.070842  38913.587000  0.915556   0.249544        7.885065  1.000000

Weighted AND sigma-clipped statistics N =  7
Column:	 ['wav_ratio', 'obs_theo_ratio', 'long_wav']
Mean:	 [1.04 0.96 0.87]
Std:	 [0.02 0.24 0.05]
SEM:	 [0.01 0.11 0.03]
N effective:	 5.65
CI 90:
 [[1.03 0.73 0.82]
 [1.06 1.19 0.92]]
CI 68:
 [[1.03 0.83 0.84]
 [1.05 1.08 0.9 ]]
t-test of value < 0.8: p = [0.     0.1117 0.019 ]


 FAR PAIRS 

Weighted statistics N =  11
Column:	 ['wav_ratio', 'obs_theo_ratio', 'long_wav']
Mean:	 [1.32 1.14 0.87]
Std:	 [0.02 0.39 0.04]
SEM:	 [0.01 0.19 0.02]
N effective:	 5.5
CI 90:
 [[1.3  0.76 0.83]
 [1.34 1.53 0.91]]
CI 68:
 [[1.31 0.94 0.85]
 [1.33 1.35 0.89]]

Sigma-clipped statistics

       Unnamed: 0  obs_theo_ratio  wav_ratio        Texcit  long_wav  rel_error  bright_product   weights
count    9.000000        9.000000   9.000000      9.000000  9.000000   9.000000        9.000000  9.000000
mean    12.444444        1.157793   1.317392  36812.256222  0.867154   0.151515        0.430815  0.389920
std      3.678013        0.188932   0.025172   4797.743719  0.045045   0.046699        0.387575  0.281120
min      7.000000        0.860897   1.286715  29228.502000  0.776849   0.083081        0.063460  0.063460
25%     10.000000        1.038736   1.292985  34288.459000  0.865016   0.117980        0.213199  0.213199
50%     12.000000        1.153847   1.326870  35613.272000  0.885066   0.147546        0.295028  0.295028
75%     15.000000        1.255317   1.338793  39219.492000  0.894615   0.193794        0.546303  0.546303
max     18.000000        1.495538   1.346180  43798.108000  0.908340   0.224645        1.368048  1.000000

Weighted AND sigma-clipped statistics N =  9
Column:	 ['wav_ratio', 'obs_theo_ratio', 'long_wav']
Mean:	 [1.32 1.1  0.87]
Std:	 [0.02 0.18 0.04]
SEM:	 [0.01 0.12 0.02]
N effective:	 3.51
CI 90:
 [[1.29 0.8  0.8 ]
 [1.36 1.39 0.93]]
CI 68:
 [[1.31 0.95 0.84]
 [1.34 1.24 0.9 ]]
t-test of value < 0.8: p = [0.0001 0.0501 0.0439]

#+end_example

**** Hand summary of the above and calculation of the extinction
:PROPERTIES:
:ID:       51B5A586-9F02-4D7C-84DC-A1538653B60E
:END:
- So we will use the weighted and sigma-clipped statistics
|             | obs/pred | w2/w1 | tau2(beta=1) | tau2(beta=2) | tau2(beta=1.4) |     A_V |     A_K |
|-------------+----------+-------+--------------+--------------+----------------+--------+--------|
| Mean + sig  |     1.16 |  1.33 |       -0.450 |       -0.193 |         -0.302 | -0.622 | -0.102 |
| Mean        |     1.02 |  1.33 |       -0.060 |       -0.026 |         -0.040 | -0.082 | -0.014 |
| Mean - sig  |     0.88 |  1.33 |        0.387 |        0.166 |          0.261 |  0.538 |  0.088 |
| 68% low lim |     0.86 |  1.33 |        0.457 |        0.196 |          0.307 |  0.632 |  0.104 |
| 95% low lim |     0.62 |  1.33 |        1.449 |        0.622 |          0.974 |  2.006 |  0.330 |
|             |          |       |              |              |                |        |        |
|             |          |       |              |              |                |        |        |
|             |          |       |              |              |                |        |        |
#+TBLFM: $4=-log($2) / ($3 - 1);f3::$5=-log($2) / ($3**2 - 1);f3::$6=-log($2) / ($3**1.4 - 1);f3::$7=$-1 2.06 ; f3::$8=$-2 0.339 ; f3::@2$2=0.14+@3::@4$2=@3-0.14
- In my ISM course notes I derived the following:
  : beta = 4.48 log(1 + 1/R_V)
- So with R_V = 2.74 for SMC we have beta = 4.48 log(1 + 1/2.74) = 1.4
- So this is the optical depth at 0.87 +/- 0.04 micron
  - A = -2.5 log10(exp(-tau)) = 2.5 log10(e) \times tau = 1.0857 tau
- V band is 0.55 micron so A_V = 1.0857 (0.87/0.55)**1.4 tau(8700) = 2.06 tau(8700)
- K band is around 2 micron so A_K = 1.0857 (0.87/2.0)**1.4 tau(8700) = 0.339 tau(8700)
- So we have deduced that
  - A_K = -0.01 +/- 0.10
  - A_V = -0.08 +/- 0.60
- Repeat after eliminating more blends
|             | obs/pred | w2/w1 | tau2(beta=1) | tau2(beta=2) | tau2(beta=1.4) |     A_V |     A_K |
|-------------+----------+-------+--------------+--------------+----------------+--------+--------|
| Mean + sig  |     1.22 |  1.33 |       -0.627 |       -0.269 |         -0.422 | -0.869 | -0.143 |
| Mean        |      1.1 |  1.33 |       -0.289 |       -0.124 |         -0.194 | -0.400 | -0.066 |
| Mean - sig  |     0.98 |  1.33 |        0.155 |        0.067 |          0.105 |  0.216 |  0.036 |
| 68% low lim |     0.95 |  1.33 |        0.155 |        0.067 |          0.105 |  0.216 |  0.036 |
| 90% low lim |      0.8 |  1.33 |        0.676 |        0.290 |          0.455 |  0.937 |  0.154 |
#+TBLFM: $4=-log($2) / ($3 - 1);f3::$5=-log($2) / ($3**2 - 1);f3::$6=-log($2) / ($3**1.4 - 1);f3::$7=$-1 2.06 ; f3::$8=$-2 0.339 ; f3::@2$2=0.12+@3::@4$2=@3-0.12
- This is worse

*** Calculate the excitation diagram for these lines
- [2024-01-22 Mon] Now that we know that the extra PDR reddening is negligible, we can calculate the excitation diagram and compare with other regions and with models
- Assuming optically thin emission, we have
  \[I_{ji} = N_j A_{ji} h\nu_{ji} / 4\pi \]
- And we want to graph \(N_j / g_j\) against excitation energy (or temperature)
  - so we just take ratios of \(I_{ji} \lambda_{ji} / A_{ji} g_j\), normalised to the brightest line
- so question is what to with g_j
  - we have 2 J + 1 for the rotation, but then  we need to multiply by O/P ratio for the odd J states (ortho states),
    where O/P = 3 for LTE, or could be 1.7 for pure UV excitation without collisions (Kaplan:2021a)
** Previous work on excitation of ro-vibrational levels in PDRs

*** Kaplan:2021a
- This seems the most recent relevant paper on the near-infrared lines
- They observe 5 regions, which include the Horse head nebula and the Orion Bar
- They detect lines up to v=14, which is the same as us
- And with v=4 they get up to J=19, which is higher than us (we maybe see up to J=13)
- They compare with a pure fluorescent spectrum, which has well separated ladders for the different v levels
  - Fluorescent spectrum has high vibrational temperature and a low rotational temperature
- The Orion Bar shows the largest deviation from this
  - Which they ascribe to collisional effects
  - They are assuming a density of 1e6 in Orion,
  - Which is way higher than what they gave in an earlier paper
    - Kaplan:2017a
    - although they never comment on this
- They look at the ortho-para ratio
  - The ortho lines have odd J
  - The para lines have even J
  - For the ground state, we expect O/P = 3 in LTE
    - But, for fluorescently excited lines, the additional optical depth increases the self-shielding for the ortho lines, which reduces the pumping efficiency and brings it down to O/P = 1.7
    - Then collisional transitions (if they are important) can take it back up to 3 again
- They determine the K-band extinction from comparing lines with shared upper levels
  - And assuming an extinction law of the form lambda^-1.8
    - Although they say that varying the index makes little difference
  - The get values around A_K = 0.7
    - Which would imply A_V = 10 if it was that steep up to the optical!
- They do show spatially resolved results
  - But hardly comment on these
  - And they are hard to interpret, since I am not sure which way their slit is going
- They do not relate the H2 lines to other lines (e.g, H I) and do not talk about the absolute flux
- 

* Previous work on optical H2 lines
- Burton:1992a is original paper
  - Fluorescent molecular hydrogen line emission in the far-red
  - Michael G. Burton,' M. Bulmer,? A. Moorhouse,' T. R. Geballe* and P. W. J. L. Brand
  - 
     : SUMMARY
     : Over 30 lines from the v = 3-0, 4-1, 7-3 and 8-4 vibrational series of the hydrogen
     : molecule have been observed from lambda = 7600-8800Ã in the reflection nebula
     : NGC 2023, originating from levels up to 41 000 K above ground. This is the first time
     : that H_2 has been observed in the optical CCD regime and these are the highest
     : excitation lines from the ground electronic state that have yet been detected. The
     : spectrum shows the characteristics expected of UV fluorescence, although in detail
     : there are some differences from model predictions. Emission from newly formed
     : molecules in v = 4 may have been detected. Strong [C I] 8727-A forbidden line
     : emission is also observed, coincident with the H_2 emission, and arising from the same
     : photodissociation region gas.
- Black:1976a Table 7 talks about far red lines
  - 
     : Tables 6 and 7 contain the predicted intensities for the model cloud
     : described above with a total linear dimension of 1018 cm. The
     : intensities of the very strongest lines produced in the cascade are
     : given in photons cm_ 2 s _ 1 s r"1 and as fractions of the total
     : ultraviolet fluorescence rate. The strongest lines in the near
     : infrared at wavelengths less than 1.0 micron are presented in Table 7. The
     : near-infrared lines tend to be less intense by factors of 50 or more
     : than the strongest lines; however, detectors in the near-infrared can
     : be more sensitive than those which operate at about 2 micron by a
     : comparable factor. The total yield of the cascade is about three
     : infrared photons emitted for each ultraviolet photon absorbed. The
     : predicted line intensities for such a cloud are comparable to the
     : present detection thresholds. A denser region exposed to a more
     : intense radiation field will produce stronger infrared emission lines.
- Neufeld:1996a give updated calculations
- 
