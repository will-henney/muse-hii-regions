* Molecular hydrogen lines at optical wavelengths
- Now that we have established that the DRLs are actually H2, we can see what physics we can do with them



** Analysis of identified lines in NGC 346

*** Read in the spreadsheet data from Google sheets
- File is exported to
  - [[file:../data/spec1d/H2 DRL identifications from Cloudy.xlsx]]
- We convert them into a bunch of YAML files
- [2023-08-05 Sat] Now we get the blend rows as well
#+begin_src python :tangle ../scripts/h2-spreadsheet-convert.py
  import pandas as pd
  import sys
  from pathlib import Path
  import typer
  import openpyxl
  import yaml
  import slugify

  def main(
          excel_file: str,
          out_folder: str="n346-lines",
  ):
      """Convert excel spreadsheet of emission lines to YAML files, one per row

      Preserves Notes and Comments on each cell
      """
      # Read in the spreadsheet
      workbook = openpyxl.load_workbook(excel_file, data_only=True)
      # And select the first sheet
      sheet = workbook.active

      # Make a list of row data from the sheet
      values_array = list(sheet.values)

      # Make sure the output folder exists
      out_path = Path(out_folder)
      out_path.mkdir(parents=True, exist_ok=True)

      # Column headers are in first row
      kwds = [
          # Try to make sure headers are valid identifiers
          slugify.slugify(str(x), lowercase=False, separator="_", replacements=[["Î»", "lambda"]])
          for x in values_array[0]
          # And skip empty columns
          if x
      ]
      # sys.exit(str(kwds))

      # Loop over all the following rows
      for index, values in enumerate(values_array[1:], start=2):
          if not any(values):
              # Skip any blank rows
              continue
          # Make a dict of the data from this row
          data = dict(zip(kwds, values))
          # Save row number in the Google Sheet for cross-referencing of blends
          data["H2_index"] = index
          # For any lines that do not have an observed counterpart ...
          if not data["wl_obs"]:
              # ... check if they are blends with next or previous
              if data["Notes"] and data["Notes"].startswith("blend with"):
                  # save pointers  to the line they are blended with
                  if "blend with prev" in data["Notes"]:
                      data["blend_index"] = index - 1
                  elif "blend with next" in data["Notes"]:
                      data["blend_index"] = index + 1
                  else:
                      continue
              else:
                  # ... othewise skip
                  continue
          # rovib quantum numbers of upper and lower states
          vhi, vlo = int(data["Vhi"]), int(data["Vlo"])
          jhi, jlo = int(data["Jhi"]), int(data["Jlo"])
          # Make a string for the transition
          transition = f"{vhi:02d}_{jhi:02d}-{vlo:02d}_{jlo:02d}"
          wavstring = slugify.slugify(data["wl_lab"], separator="")
          # Save the data to a YAML file
          with open(out_path / f"{index:04d}-{transition}-{wavstring}.yaml", "w") as f:
              yaml.dump(data, f, allow_unicode=True, sort_keys=False, default_flow_style=False)



  if __name__ == "__main__":
      typer.run(main)

#+end_src

#+begin_src sh :dir ../data :results verbatim
  python ../scripts/h2-spreadsheet-convert.py "spec1d/H2 DRL identifications from Cloudy.xlsx" --out-folder n346-h2-lines
#+end_src

#+RESULTS:

*** Merge the H2 ids with the unidentified list

**** First, we switch the yaml files to a pandas data frame
#+begin_src python :eval no :tangle ../scripts/h2-collate-lines.py
  import numpy as np
  import yaml
  from pathlib import Path
  import pandas as pd
  import typer
  import sys

  def main(data_dir: str="n346-h2-lines"):
        # Next, get all the lines into a big list of dicts
        line_files = sorted(Path(data_dir).glob("*.yaml"))
        data = [
              yaml.safe_load(path.open()) for path in line_files
        ]
        df0 = pd.DataFrame(data)
        df0.to_csv(Path(data_dir) / "h2-line-ids.csv")

  if __name__ == "__main__":
      typer.run(main)

#+end_src

#+begin_src sh :dir ../data :results none
  python ../scripts/h2-collate-lines.py
#+end_src

This writes the results to [[file:../data/n346-h2-lines/h2-line-ids.csv]]

**** Combine the H2 ids with the previous table of UILs
- This uses the uil-final-table.csv that we generated in [[id:8CCFF185-E205-42F0-9278-4E46DE184262][Make a table of rest wavelengths plus uncertainties of all the UILs]] of [[file:ngc-346-drl-spectra.org][file:~/Dropbox/muse-hii-regions/docs/ngc-346-drl-spectra.org]]
- We use ~pd.merge_asof()~ to do a fuzzy join on the wavelength column
  - This is necessary since an exact join had corner cases with rounding problems (e.g., 0.99 vs 1.00)
- We filter out the blend rows for this case, since we cannot easily deal with them
#+begin_src python :eval no :tangle ../scripts/h2-combine-tables.py
  import numpy as np
  import yaml
  from pathlib import Path
  import pandas as pd
  import typer
  import sys
  COLS = ["H2_line", "wl_lab", "wl_obs", "Notes"]
  def main(
              data_dir: str="n346-h2-lines",
              orig_data_dir: str="n346-lines/all-lines-c007-chop-mean",
  ):
        df1 = pd.read_csv(Path(orig_data_dir) / "uil-final-table.csv")
        df2 = pd.read_csv(Path(data_dir) / "h2-line-ids.csv")
        df2 = df2[COLS].sort_values("wl_obs").dropna(subset=["wl_obs"])
        df0 = pd.merge_asof(df1, df2, left_on="wave0", right_on="wl_obs", direction="nearest", tolerance=1.0)
        df0.to_csv(Path(data_dir) / "h2-final-table.csv")
        print(df0)

  if __name__ == "__main__":
      typer.run(main)

#+end_src

#+begin_src sh :dir ../data :results output verbatim
  COLUMNS=1000 python ../scripts/h2-combine-tables.py
#+end_src

#+RESULTS:
#+begin_example
     Index        wave0  sig_wave0      flux  sig_flux            Type  blend     I / 0             E(I / 0)     II / 0            E(II / 0)  MYSO / 0          E(MYSO / 0)    H2_line    wl_lab   wl_obs           Notes
0     1146  6029.569455   0.514152  0.030460  0.004393   Deep Neutral?  False  0.806796   0.2783544695494928   0.662888                    <  0.566409  0.10944291146839161   7-2 S(7)  6029.57A  6029.57             NaN
1     1153  6037.396888   0.514820  0.041788  0.003967   Deep Neutral?  False  0.477559                    <   0.453518                    <  0.621762  0.14597441811223902   7-2 S(1)  6037.46A  6037.40             NaN
2     1190  6083.195649   0.518725  0.010027  0.004825        Neutral?  False  1.655362                    <   1.854600                    <  1.587017   0.7719142568089383   7-2 S(0)  6083.08A  6083.20             NaN
3     1300  6221.819532   0.530546  0.044434  0.002802    Deep Neutral  False  0.253526                    <   0.543340                    <  0.646933  0.08354545607085527   4-0 S(5)  6221.63A  6221.82             NaN
4     1332  6261.684680   0.533945  0.027879  0.002361   Deep Neutral?  False  2.198663  0.29708825322477167   0.453927  0.10180843302574635  0.528582   0.3176379358431232  12-5 S(1)  6261.73A  6261.68   High T(excit)
..     ...          ...        ...       ...       ...             ...    ...       ...                  ...        ...                  ...       ...                  ...        ...       ...      ...             ...
109   3640  9145.250748   0.470866  0.173619  0.022533    Deep Neutral  False  0.250861                    <   0.245631  0.10120057582603312  0.499748  0.25571329399302484   9-5 S(1)  9145.66A  9145.25             NaN
110   3649  9155.283022   0.780688  0.091543  0.017510   Deep Neutral?  False  0.343321  0.12688119030418255   0.285899  0.08124287479567108  0.145526                    <   4-1 Q(4)  9155.56A  9155.28             NaN
111   3654  9162.896677   0.781337  0.033448  0.008285   Deep Neutral?  False  0.508610                    <  19.891807                    <  0.364105                    <   9-5 S(7)  9162.58A  9162.90             NaN
112   3736  9264.376659   0.789990  0.040371  0.006785  Deep Neutral??  False  0.758882  0.45368481338933114   0.234097  0.06263303203717613  0.624451  0.29546207986604506   9-5 S(8)  9264.11A  9264.38             NaN
113   3762  9297.368030   0.274485  0.249847  0.007631   Deep Neutral?  False  0.515155                    <   0.215652                    <  0.798834  0.07081402869730503   4-1 O(2)  9297.59A  9297.37  blend 8-4 Q(8)

[114 rows x 17 columns]
#+end_example

**** Write a latex table of all the H2 lines
- This is a repeat of [[id:028D1B5F-C4A1-4689-83FB-4B1FA7FB6F60][Write a latex version of the table]] in [[file:ngc-346-drl-spectra.org]]
- But with extra columns for the line label and rest wavelength


#+begin_src python :eval no :tangle ../scripts/convert-table-h2-latex.py
  import pandas as pd
  import numpy as np


  def format_blend(value, dp=2):
      if not value or not np.isfinite(value):
          return "0.0:"
      try:
          return str(round(float(value), dp)) + ":"
      except TypeError:
          return "0.0:"

  def format_float(value, dp):
      return f"{round(float(value), dp):.{dp}f}"

  def format_pair(value, uncertainty, dp=2):
      if not value or not np.isfinite(value):
          return "0.0"
      try:
          svalue = str(round(float(value), dp))
      except TypeError:
          svalue = "0.0"

      if uncertainty in ["<", ">"]:
          return f"{uncertainty} {svalue}"

      try:
          suncertainty = str(round(float(uncertainty), dp))
      except TypeError:
          suncertainty = "0.0"

      return rf"{svalue} \pm {suncertainty}"


  df = pd.read_csv("h2-final-table.csv")
  table = []
  for _, row in df.iterrows():
      if row["blend"]:
          table.append(
              {
                  r"\lambda(\text{obs})": format_blend(row["wave0"]),
                  r"Transition": row["H2_line"],
                  r"\lambda(\text{rest})": format_float(str(row["wl_lab"]).rstrip("A"), dp=2),
                  r"I(\hb = 100)": format_blend(row["flux"], 3),
                  r"\mathrm{I / 0}": "",
                  r"\mathrm{II / 0}": "",
                  r"\mathrm{MYSO / 0}": "",
              }
          )
      else:
          table.append(
              {
                  r"\lambda(\text{obs})": format_pair(row["wave0"], row["sig_wave0"]),
                  r"Transition": row["H2_line"],
                  r"\lambda(\text{rest})": format_float(str(row["wl_lab"]).rstrip("A"), dp=2),
                  r"I(\hb = 100)": format_pair(row["flux"], row["sig_flux"], 3),
                  r"\mathrm{I / 0}": format_pair(row["I / 0"], row["E(I / 0)"]),
                  r"\mathrm{II / 0}": format_pair(row["II / 0"], row["E(II / 0)"]),
                  r"\mathrm{MYSO / 0}": format_pair(
                      row["MYSO / 0"], row["E(MYSO / 0)"]
                  ),
              }
          )
      dff = pd.DataFrame(table)  

  s = dff.style.hide()


  with open("h2-final-table.tex", "w") as f:
      f.write(
          s.to_latex(
              hrules=True,
              siunitx=False,
              environment="longtable",
              column_format="RrR RRRR",
          )
      )
#+end_src

#+begin_src sh :dir ../data/n346-h2-lines :results output verbatim
  python ../../scripts/convert-table-h2-latex.py
#+end_src

#+RESULTS:

*** Merge the H2 lines with the full line list
- I am thinking that instead of giving two tables (H2 lines, then atomic/ionic lines) it would be better to put everything in a single table


**** DONE Make a table of known lines plus H2 lines
CLOSED: [2023-08-05 Sat 21:39]
- So this is a variation on [[id:58DE61EF-5582-4FC5-AE48-BB29BFA9953C][Make a table of all the known lines]] in [[file:ngc-346-drl-spectra.org]]
- The first change is to stop dropping the UIL entries
  - Instead, we will look for H2 identifications for them
- Also, we merge with the theoretical H2 lines table
- And construct the spectroscopic IDs for the lines
- We are now well-placed for dealing with the blends, which we will do when we export the latex table below


#+begin_src python :eval no :tangle ../scripts/make-table-known-lines-with-h2.py
  from pathlib import Path
  import yaml
  import pandas as pd
  import numpy as np
  import pyneb as pn
  import typer
  import astropy.constants as const  # type: ignore
  import astropy.units as u  # type: ignore

  LIGHT_SPEED_KMS = const.c.to(u.km / u.s).value
  UNWANTED_ZONES = ["zone-S"]
  UNWANTED_TYPES = ["Unidentified"]

  REPLACEMENTS = {
      "Deep": "Deep Neutral",
      "Fe": "Fe-Ni-Ca-Si",
  }
  BEST_TYPES = {
      "zone-0": ["Deep", "Neutral", "Low", "Med"],
      "zone-I": ["Neutral", "Low", "Med", "Fe"],
      "zone-II": ["Low", "Med", "Fe"],
      "zone-III": ["Med", "Fe"],
      "zone-IV": ["Med", "High"],
      "zone-MYSO": ["Deep", "Neutral", "Low", "Med", "Fe"],
      "zone-S": ["Med"],
  }
  H2_COLS = ["H2_line", "wl_lab", "wl_obs", "Notes", "H2_index"]

  # Find intrinsic Balmer decrement
  hi = pn.RecAtom("H", 1)
  tem, den = 12500, 100
  R0 = hi.getEmissivity(tem, den, wave=6563) / hi.getEmissivity(tem, den, wave=4861)
  # Set up reddening law for SMC
  rc = pn.RedCorr()
  rc.R_V = 2.74
  rc.FitzParams = [-4.96, 2.26, 0.39, 0.6, 4.6, 1.0]
  rc.law = "F99"


  def main(
      id_label: str,
      debug: bool = False,
      minimum_signal_noise: float = 3.0,
      zone_file: str = "zones.yaml",
      h2_data_dir: str = "n346-h2-lines",
      orig_data_dir: str = "n346-lines",
      vsys: float = 171.1,
      d_vsys: float = 5.0,
  ):
      """Table of all identified lines"""

      # Load the zone database
      with open(Path(orig_data_dir) / zone_file) as f:
          # But drop zones we do not want
          zones = [_ for _ in yaml.safe_load(f) if _["label"] not in UNWANTED_ZONES]

      # Iterate over the zones
      wstrings = []
      for jzone, zone in enumerate(zones):
          # Read in the velocity table
          df = pd.read_csv(
              Path(orig_data_dir) / f"all-lines-{id_label}/{zone['label']}-velocities.csv"
          ).set_index("Index")
          if zone == zones[0]:
              # Initialize the output table
              df0 = df[["Type", "ID", "blend"]]
          # Columns of wavelength and flux for each zone, with their respective errors
          eflux = df.flux / df.s_n
          zstring = zone["label"].split("-")[1]
          flabel = f"F({zstring})"
          elabel = f"E({zstring})"
          wlabel = f"W({zstring})"
          dwlabel = f"dW({zstring})"
          # Save a list of the wavelength columns
          wstrings.append(wlabel)
          # Calculate the reddening correction from H alpha, which is channel 1573
          obs_decrement = df.loc[1573].flux / 100.0
          rc.setCorr(obs_decrement / R0, wave1=6563, wave2=4861)
          correction = rc.getCorr(df.wave) / rc.getCorr(df.loc[211].wave)
          # Add the 4 columns to the output table
          df0 = df0.assign(
              ,**{
                  wlabel: df.wave / (1 + vsys / LIGHT_SPEED_KMS),
                  dwlabel: df.e_wave,
                  flabel: correction * df.flux,
                  elabel: correction * eflux,
              }
          )
          # Ignore values with s/n that is too low or that are not of the best type for this zone
          mask = (df.s_n < minimum_signal_noise) | ~df.Type.str.startswith(
              tuple(BEST_TYPES[zone["label"]])
          )
          for label in [wlabel, dwlabel, flabel, elabel]:
              df0.loc[mask, label] = np.nan
      # Second pass: consolidate to a single wavelength column
      dwstrings = ["d" + _ for _ in wstrings]
      # Average over valid zones
      df0.insert(4, "wave", np.nanmean(df0[wstrings], axis=1))
      # And use the smallest for wave error
      df0.insert(5, "e_wave", np.nanmin(df0[dwstrings], axis=1))
      # Drop the individual wavelength columns
      df0 = df0.drop(columns=wstrings + dwstrings)
      # And drop lines with no wavelength
      df0 = df0[np.isfinite(df0.wave)]

      #
      # Add in the H2 lines
      #

      df2 = pd.read_csv(Path(h2_data_dir) / "h2-line-ids.csv")
      df2 = df2[H2_COLS].sort_values("wl_obs").dropna(subset=["wl_obs"])
      df0 = pd.merge_asof(
          df0, df2, left_on="wave", right_on="wl_obs", direction="nearest", tolerance=1.0
      )
      # Select the lines formerly unidentified
      h2mask = df0.ID.str.startswith("UIL")

      # Construct the ID description for the H2 lines
      df0.loc[h2mask, "ID"] = (
          "H_2 " + df0.loc[h2mask, "H2_line"] + " " + df0.loc[h2mask, "wl_lab"]
      )
      # And remove the extraneous columns
      df0 = df0.drop(columns=["H2_line", "wl_lab"])

      print(df0.loc[h2mask])
      df0.to_csv(Path(h2_data_dir) / "known-lines-with-h2-final-table.csv")


  if __name__ == "__main__":
      typer.run(main)
#+end_src

#+begin_src sh :dir ../data :results output verbatim
  COLUMNS=1000 python ../scripts/make-table-known-lines-with-h2.py c007-chop-mean --minimum-signal-noise 1.0
#+end_src

#+RESULTS:
#+begin_example
               Type                      ID  blend         wave    e_wave      F(0)      E(0)  F(I)  E(I)  F(II)  E(II)  F(III)  E(III)  F(IV)  E(IV)   F(MYSO)   E(MYSO)   wl_obs           Notes  H2_index
41    Deep Neutral?   H_2 7-2 S(7) 6029.57A  False  6029.501644  0.160755  0.026172  0.003774   NaN   NaN    NaN    NaN     NaN     NaN    NaN    NaN  0.014860  0.001911  6029.57             NaN     173.0
42    Deep Neutral?   H_2 7-2 S(1) 6037.46A  False  6037.212893  0.118675  0.035879  0.003406   NaN   NaN    NaN    NaN     NaN     NaN    NaN    NaN  0.022362  0.004802  6037.40             NaN     175.0
44         Neutral?   H_2 7-2 S(0) 6083.08A  False  6083.532257  0.087536  0.008571  0.004125   NaN   NaN    NaN    NaN     NaN     NaN    NaN    NaN  0.013754  0.000963  6083.20             NaN     180.0
46     Deep Neutral   H_2 4-0 S(5) 6221.63A  False  6221.804241  0.078828  0.037499  0.002365   NaN   NaN    NaN    NaN     NaN     NaN    NaN    NaN  0.023332  0.002593  6221.82             NaN     199.0
48    Deep Neutral?  H_2 12-5 S(1) 6261.73A  False  6262.122680  0.105880  0.023445  0.001986   NaN   NaN    NaN    NaN     NaN     NaN    NaN    NaN  0.012425  0.007392  6261.68   High T(excit)     205.0
..              ...                     ...    ...          ...       ...       ...       ...   ...   ...    ...    ...     ...     ...    ...    ...       ...       ...      ...             ...       ...
240    Deep Neutral                     NaN  False  9144.056929  0.162228  0.124354  0.016139   NaN   NaN    NaN    NaN     NaN     NaN    NaN    NaN  0.062477  0.030923      NaN             NaN       NaN
241   Deep Neutral?   H_2 4-1 Q(4) 9155.56A  False  9155.283022  0.239097  0.065545  0.012537   NaN   NaN    NaN    NaN     NaN     NaN    NaN    NaN       NaN       NaN  9155.28             NaN     688.0
242   Deep Neutral?   H_2 9-5 S(7) 9162.58A  False  9162.896677  0.309601  0.023943  0.005930   NaN   NaN    NaN    NaN     NaN     NaN    NaN    NaN       NaN       NaN  9162.90             NaN     691.0
248  Deep Neutral??   H_2 9-5 S(8) 9264.11A  False  9263.615044  0.210080  0.028802  0.004841   NaN   NaN    NaN    NaN     NaN     NaN    NaN    NaN  0.018082  0.007998  9264.38             NaN     708.0
249   Deep Neutral?   H_2 4-1 O(2) 9297.59A  False  9297.275883  0.038180  0.178056  0.005439   NaN   NaN    NaN    NaN     NaN     NaN    NaN    NaN  0.140809  0.011693  9297.37  blend 8-4 Q(8)     711.0

[115 rows x 20 columns]
#+end_example



**** TODO Write big LaTeX table of all the lines including H2

** Previous work on excitation of ro-vibrational levels in PDRs

*** Kaplan:2021a
- This seems the most recent relevant paper on the near-infrared lines
- They observe 5 regions, which include the Horse head nebula and the Orion Bar
- They detect lines up to v=14, which is the same as us
- And with v=4 they get up to J=19, which is higher than us (we maybe see up to J=13)
- They compare with a pure fluorescent spectrum, which has well separated ladders for the different v levels
  - Fluorescent spectrum has high vibrational temperature and a low rotational temperature
- The Orion Bar shows the largest deviation from this
  - Which they ascribe to collisional effects
  - They are assuming a density of 1e6 in Orion,
  - Which is way higher than what they gave in an earlier paper
    - Kaplan:2017a
    - although they never comment on this
- They look at the ortho-para ratio
  - The ortho lines have odd J
  - The para lines have even J
  - For the ground state, we expect O/P = 3 in LTE
    - But, for fluorescently excited lines, the additional optical depth increases the self-shielding for the ortho lines, which reduces the pumping efficiency and brings it down to O/P = 1.7
    - Then collisional transitions (if they are important) can take it back up to 3 again
- They determine the K-band extinction from comparing lines with shared upper levels
  - And assuming an extinction law of the form lambda^-1.8
    - Although they say that varying the index makes little difference
  - The get values around A_K = 0.7
    - Which would imply A_V = 10 if it was that steep up to the optical!
- They do show spatially resolved results
  - But hardly comment on these
  - And they are hard to interpret, since I am not sure which way their slit is going
- They do not relate the H2 lines to other lines (e.g, H I) and do not talk about the absolute flux

