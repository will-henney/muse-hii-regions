* Maps of all lines from the PZ cube
- Find what steps need to be repeated from the list in [[file:ngc-346-drl-spectra.org]]
  - Continuum subtraction ([[id:59F3D73A-6179-462C-86E8-1F915C76E274][Step -1]])
  - Maps of different lines ([[id:B915BA48-D7C9-4FFE-9ECF-511CBF1A4ED7][Step 4]])
** Continuum subtraction
- This uses the median filter method
- Previously, filtered cube files had been written out to [[file:../big-data/ngc346new/]]
  - I might as well write them out in same place, but with a different prefix
#+begin_src sh :dir ../big-data/ngc346new/ :results output verbatim :eval no
  time python ../../lib/median_continuum.py\
       --two-pass \
       --out-prefix n346-PZ-2pass \
       --cube-name PeterZeidler/DATACUBE_FINAL_fwhm_cor.fits \
       11
#+end_src

#+RESULTS:
: /Users/will/Dropbox/muse-hii-regions/big-data/ngc346new

- I have repeated this for window widths of 7, 11, 101
** Image maps


*** First try and make the rainbow maps
Start off with the ESO cube. This differs from what we did previously in that it uses the 2pass 007 filtered cube
#+begin_src sh :dir ../data/spec1d :results output file
  python ../../scripts/peak-image-plot.py \
         ../../big-data/ngc346new/n346-muse-2pass-csub-007.fits \
         n346-nostar-bs-peaks-p0010-d0030.csv \
         --ncolumns 8 \
         --no-subtract-base \
         --wavelength-window-pad 0.5 \
         --extra-suffix ESO007
#+end_src

#+RESULTS:
[[file:/Users/will/Dropbox/muse-hii-regions/data/spec1d/peak-images-n346-nostar-bs-peaks-p0010-d0030-ESO007.pdf]]

Now the PZ one

#+begin_src sh :dir ../data/spec1d :results output file
  python ../../scripts/peak-image-plot.py \
         ../../big-data/ngc346new/n346-PZ-2pass-csub-007.fits \
         n346-nostar-bs-peaks-p0010-d0030.csv \
         --ncolumns 8 \
         --no-subtract-base \
         --wavelength-window-pad 0.5 \
         --extra-suffix PZ007
#+end_src

#+RESULTS:
[[file:/Users/will/Dropbox/muse-hii-regions/data/spec1d/peak-images-n346-nostar-bs-peaks-p0010-d0030-PZ007.pdf]]

That one is OK

#+begin_src sh :dir ../data/spec1d :results output file
  python ../../scripts/peak-image-plot.py \
         ../../big-data/ngc346new/n346-PZ-2pass-csub-007.fits \
         n346-nostar-bs-peaks-p0010-d0030.csv \
         --ncolumns 8 \
         --subtract-base \
         --wavelength-window-pad 0.5 \
         --extra-suffix PZ007B
#+end_src

#+RESULTS:
[[file:/Users/will/Dropbox/muse-hii-regions/data/spec1d/peak-images-n346-nostar-bs-peaks-p0010-d0030-PZ007B.pdf]]

That one is terrible. We should not subtract the base

#+begin_src sh :dir ../data/spec1d :results output file
  python ../../scripts/peak-image-plot.py \
         ../../big-data/ngc346new/n346-PZ-2pass-csub-101.fits \
         n346-nostar-bs-peaks-p0010-d0030.csv \
         --ncolumns 8 \
         --no-subtract-base \
         --wavelength-window-pad 0.5 \
         --extra-suffix PZ101
#+end_src

#+RESULTS:
[[file:/Users/will/Dropbox/muse-hii-regions/data/spec1d/peak-images-n346-nostar-bs-peaks-p0010-d0030-PZ101.pdf]]

And that one is mostly fine too. 
*** Now make the individual maps
- It turns out that the [[file:../scripts/make-one-map.py][make-one-map.py]] script uses info from the spreadsheet to decide how to extract the line and from which median-filtered image.
- I would rather use a homogeneous approach this time
**** New version of map script
#+begin_src python :tangle ../scripts/make-one-map-2024.py
  import numpy as np
  import sys
  from pathlib import Path
  import typer
  import yaml
  import slugify
  from text_unidecode import unidecode
  from astropy.io import fits
  from astropy.wcs import WCS

  unwanted_types = ["sky",  "telluric", "noise", "nan"]

  def get_line_type(s):
      ltype = slugify.slugify(str(s).rstrip("?"))
      if ltype in unwanted_types:
          return None
      else:
          return ltype


  def load_cube_hdu(
          cwindow: int,
          prefix: str="n346-muse-csub",
          big_data_folder: Path=Path("../../big-data/ngc346new"),
  ):
      cube_path = big_data_folder / f"{prefix}-{cwindow:03d}.fits"
      return fits.open(cube_path)[0]

  def get_id_string(data):
      s = f"{data['Index']:04d}-"
      s += slugify.slugify(data["ID"])
      if "UIL" in data["ID"]:
          s += "-" + slugify.slugify(f"{data['lambda_HM']:.2f}")
      return s

  def choose_cont_window(data: dict) -> tuple[int, bool]:
      """Decide which type of continuum subtraction is preferred

      Returns tuple: width of window, and whether to subtract baseline
      """

      # Case of no preference given
      if not data["Cont_method"]:
          # Just use the wide window
          return 101, False

      try:
          # Case of only one method listed and it is an integer
          return int(data["Cont_method"]), False
      except ValueError:
          # Case of various methods listed, or one that contains letters. Take the first
          cont_methods = data["Cont_method"].split(",")
          first_cont_method = cont_methods[0]
          if first_cont_method.endswith("B"):
              # Case that we want to subtract the baseline
              return int(first_cont_method.rstrip("B")), True
          else:
              # Case that we do not
              return int(first_cont_method), False



  def main(
          yaml_file : str,
  ):
      """Create map of a single emission line from data in YAML file
      """
      if not yaml_file.endswith(".yaml"):
          yaml_file = yaml_file + ".yaml"
      with open(yaml_file) as f:
          metadata = yaml.load(f)

      # Group all lines of same type into their own folder
      line_type = get_line_type(metadata["Type"])
      save_path = Path("type-" + line_type)
      save_path.mkdir(exist_ok=True)

      cwindow, yes_sub_base = choose_cont_window(metadata)
      cube = load_cube_hdu(cwindow)
      ipeak = metadata["Index"]
      # First try: just use 3 pixels along wave axis
      cube_window = cube.data[ipeak-1:ipeak+2, ...]
      if yes_sub_base:
          # This will fail if the line is broad
          base = 0.5 * (cube.data[ipeak-2, ...] + cube.data[ipeak+2, ...])
          cube_window -= base
      image = np.sum(cube_window, axis=0)
      header = WCS(cube.header).celestial.to_header()
      # FITS headers allow only ASCII strings
      header.update({k: unidecode(str(v)) for k, v in metadata.items()})

      fits_file = get_id_string(metadata) + ".fits"
      fits.PrimaryHDU(header=header, data=image).writeto(save_path / fits_file, overwrite=True)
      print("Image saved to", save_path / fits_file)

  if __name__ == "__main__":
      typer.run(main)

#+end_src

#+begin_src sh :dir ../data/n346-lines :results verbatim
  python ../../scripts/make-one-map.py all-lines-orig/3711.yaml
#+end_src

#+RESULTS:
: Image saved to type-deep-neutral/3711-uil-9233-46.fits


#+begin_src sh :dir ../data/n346-lines :results verbatim
python ../../scripts/make-one-map.py all-lines-orig/1547.yaml
#+end_src

#+RESULTS:
: Image saved to type-low-neb/1547-uil-6529-50.fits



#+begin_src sh :dir ../data/n346-lines :results verbaatim
python ../../scripts/make-one-map.py --help 
#+end_src


