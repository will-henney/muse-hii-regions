{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f527b119",
   "metadata": {},
   "source": [
    "# Test of mosaicking together the 30 Dor fields: A, B, C, & D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41dab45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from mpdaf.obj import Image\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS\n",
    "import reproject\n",
    "\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_color_codes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d15de2",
   "metadata": {},
   "source": [
    "## Define the target WCS for mosaicking the 4 fields together\n",
    "\n",
    "Use the image from Castro to define the WCS for reprojection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e99d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic_ha_hdulist = fits.open(\"../data/MUSE_R136toWill/GAUS_Ha6562.8_060_Will.fits\")\n",
    "mosaic_ha_hdulist.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e8415",
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic_hdr = mosaic_ha_hdulist[1].header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5e5931",
   "metadata": {},
   "source": [
    "Note that the header still refers to a 3rd dimension, even though this is just an image.  We need to remove all the keywords that mention dimension 3 so that the reprojection will work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab9a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "del mosaic_hdr[\"*3\"]\n",
    "del mosaic_hdr[\"CD3_*\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153c1761",
   "metadata": {},
   "source": [
    "## Test with the Hβ image.\n",
    "\n",
    "First we make an HDU of each field for the full mosaic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a11c31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pieces = {}\n",
    "for field in \"ABCD\":\n",
    "    infile = f\"../data/lmc-30dor-{field}-hi-4861-bin01-sum.fits\"\n",
    "    hdu = fits.open(infile)[\"DATA\"]\n",
    "    del hdu.header[\"*3\"]\n",
    "    del hdu.header[\"CD3_*\"]\n",
    "    newdata, footprint = reproject.reproject_interp(\n",
    "        hdu,\n",
    "        mosaic_hdr,\n",
    "    )\n",
    "    pieces[field] = newdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc868548",
   "metadata": {},
   "source": [
    "Plot each piece on top of one another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d2885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    figsize=(10, 10),\n",
    "    subplot_kw=dict(projection=WCS(mosaic_hdr)),\n",
    ")\n",
    "vmax = 5e5\n",
    "ax.imshow(pieces[\"A\"], vmin=0, vmax=vmax)\n",
    "ax.imshow(pieces[\"B\"], vmin=0, vmax=vmax)\n",
    "ax.imshow(pieces[\"C\"], vmin=0, vmax=vmax)\n",
    "ax.imshow(pieces[\"D\"], vmin=0, vmax=vmax)\n",
    "ax.set_title(\"Hβ overlapping pieces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a26fed",
   "metadata": {},
   "source": [
    "That looks fine - the edges of the pieces show slight artifacts, but they are not very noticeable.\n",
    "\n",
    "Now try combining the images with median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b7449",
   "metadata": {},
   "outputs": [],
   "source": [
    "combo = np.nanmedian(\n",
    "    np.stack(list(pieces.values())),\n",
    "    axis=0,\n",
    ")\n",
    "combo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0620bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    figsize=(10, 10),\n",
    "    subplot_kw=dict(projection=WCS(mosaic_hdr)),\n",
    ")\n",
    "vmax = 5e5\n",
    "ax.imshow(combo, vmin=0, vmax=vmax)\n",
    "ax.set_title(\"Hβ median mosaic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf19150",
   "metadata": {},
   "source": [
    "This time the artifacts are even less visible.\n",
    "\n",
    "We do seem to cut off a small amount of the lower left field at the bottom.\n",
    "\n",
    "## Compare with the Hα image from Castro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb5a2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    figsize=(10, 10),\n",
    "    subplot_kw=dict(projection=WCS(mosaic_hdr)),\n",
    ")\n",
    "haflux = mosaic_ha_hdulist[1].data * mosaic_ha_hdulist[3].data\n",
    "ax.imshow(haflux, vmin=0, vmax=10e5)\n",
    "ax.set_title(\"Hα from Castro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    figsize=(10, 10),\n",
    "    subplot_kw=dict(projection=WCS(mosaic_hdr)),\n",
    ")\n",
    "haflux = mosaic_ha_hdulist[1].data * mosaic_ha_hdulist[3].data\n",
    "decrement = haflux / combo\n",
    "ax.imshow(decrement, vmin=1.5, vmax=6.0)\n",
    "ax.contour(\n",
    "    haflux,\n",
    "    levels=[2.5e5, 5e5, 10e5],\n",
    "    linewidths=[0.5, 1.0, 1.5],\n",
    "    colors=\"w\",\n",
    ")\n",
    "ax.contour(2 * combo, levels=[2.5e5, 5e5, 10e5], linewidths=[0.5, 1.0, 1.5], colors=\"r\")\n",
    "ax.set_title(\"Hα / Hβ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf2207c",
   "metadata": {},
   "source": [
    "It looks like there is an astrometric offset here\n",
    "\n",
    "The Castro paper says that they based the astrometric calibration on catalog of Selman (1999).\n",
    "\n",
    "There is a line-emitting star near the center, which we could use to adjust the astrometry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf323bf",
   "metadata": {},
   "source": [
    "## Try and fix the astrometry\n",
    "\n",
    "I looked at the same star on the Castro images and on our images (field A) and got the coordinates from DS9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02472c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "c_castro = SkyCoord(ra=84.6602735, dec=-69.1035065, unit=\"deg\")\n",
    "c_eso = SkyCoord(ra=84.6599803, dec=-69.1036748, unit=\"deg\")\n",
    "\n",
    "Shift_1 = c_castro.ra - c_eso.ra\n",
    "Shift_2 = c_castro.dec - c_eso.dec\n",
    "Shift_1.deg, Shift_2.deg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f5144e",
   "metadata": {},
   "source": [
    "It looks like field C has a slightly different shift.  I am using a different star for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c7438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_castro_C = SkyCoord(84.6689140, -69.0992165, unit=\"deg\")\n",
    "c_eso_C = SkyCoord(84.6684931, -69.0995408, unit=\"deg\")\n",
    "\n",
    "Shift_1C = c_castro_C.ra - c_eso_C.ra\n",
    "Shift_2C = c_castro_C.dec - c_eso_C.dec\n",
    "Shift_1C.deg, Shift_2C.deg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b15f49",
   "metadata": {},
   "source": [
    "We need to add these to the `CRVAL` of our images in order to align with Castro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd22c9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pieces = []\n",
    "for field in \"ABCD\":\n",
    "    infile = f\"../data/lmc-30dor-{field}-hi-4861-bin01-sum.fits\"\n",
    "    hdu = fits.open(infile)[\"DATA\"]\n",
    "    del hdu.header[\"*3\"]\n",
    "    del hdu.header[\"CD3_*\"]\n",
    "    if field == \"C\":\n",
    "        hdu.header[\"CRVAL1\"] += Shift_1C.deg\n",
    "        hdu.header[\"CRVAL2\"] += Shift_2C.deg\n",
    "    else:\n",
    "        hdu.header[\"CRVAL1\"] += Shift_1.deg\n",
    "        hdu.header[\"CRVAL2\"] += Shift_2.deg\n",
    "\n",
    "    newdata, footprint = reproject.reproject_interp(\n",
    "        hdu,\n",
    "        mosaic_hdr,\n",
    "    )\n",
    "    pieces.append(newdata)\n",
    "combo = np.nanmedian(\n",
    "    np.stack(pieces),\n",
    "    axis=0,\n",
    ")\n",
    "combo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db2faec",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    figsize=(10, 10),\n",
    "    subplot_kw=dict(projection=WCS(mosaic_hdr)),\n",
    ")\n",
    "haflux = mosaic_ha_hdulist[1].data * mosaic_ha_hdulist[3].data\n",
    "decrement = haflux / combo\n",
    "ax.imshow(decrement, vmin=1.5, vmax=6.0)\n",
    "ax.contour(\n",
    "    haflux,\n",
    "    levels=[2.5e5, 5e5, 10e5],\n",
    "    linewidths=[0.5, 1.0, 1.5],\n",
    "    colors=\"w\",\n",
    ")\n",
    "ax.contour(2 * combo, levels=[2.5e5, 5e5, 10e5], linewidths=[0.5, 1.0, 1.5], colors=\"r\")\n",
    "ax.set_title(\"Hα / Hβ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121c08a9",
   "metadata": {},
   "source": [
    "That looks a lot better.  Look at it again with emphasis on the lower extinction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd530e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(\n",
    "    figsize=(10, 10),\n",
    "    subplot_kw=dict(projection=WCS(mosaic_hdr)),\n",
    ")\n",
    "haflux = mosaic_ha_hdulist[1].data * mosaic_ha_hdulist[3].data\n",
    "decrement = haflux / combo\n",
    "ax.imshow(decrement, vmin=1.5, vmax=3.0)\n",
    "ax.contour(\n",
    "    haflux,\n",
    "    levels=[2.5e5, 5e5, 10e5],\n",
    "    linewidths=[0.5, 1.0, 1.5],\n",
    "    colors=\"w\",\n",
    ")\n",
    "ax.contour(2 * combo, levels=[2.5e5, 5e5, 10e5], linewidths=[0.5, 1.0, 1.5], colors=\"r\")\n",
    "ax.set_title(\"Hα / Hβ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf6fdab",
   "metadata": {},
   "source": [
    "In the left-hand 2 fields, the alignment is not perfect.  We could maybe fix this by looking at the continuum images, but I will leave it for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001de2e9",
   "metadata": {},
   "source": [
    "## Now process all the emission lines and save them to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56e040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "afiles = sorted(Path(\"../data\").glob(\"lmc-30dor-A-*bin01-*.fits\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ade0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "[_ for _ in afiles if \"-sum\" in str(_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b375e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_p(a, b, check_mtime=False):\n",
    "    \"\"\"Return True iff path `a` exists but `b` does not\n",
    "    \n",
    "    Additionally, if `check_mtime` is true, then also update if `a` is newer than `b`\n",
    "    \"\"\"\n",
    "    A = Path(a)\n",
    "    B = Path(b)\n",
    "    if A.exists():\n",
    "        if B.exists():\n",
    "            if check_mtime:\n",
    "                return A.stat().st_mtime > B.stat().st_mtime\n",
    "            else:\n",
    "                return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7555b239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493e91bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for afile in afiles:\n",
    "    pieces = []\n",
    "    outfile = str(afile).replace(\"-A-\", \"-ABCD-\")\n",
    "    if not update_p(afile, outfile):\n",
    "        continue\n",
    "    print(f\"{afile} -> {outfile}\")\n",
    "    for field in \"ABCD\":\n",
    "        infile = str(afile).replace(\"-A-\", f\"-{field}-\")\n",
    "        hdu = fits.open(infile)[\"DATA\"]\n",
    "        del hdu.header[\"*3\"]\n",
    "        del hdu.header[\"CD3_*\"]\n",
    "        if field == \"C\":\n",
    "            hdu.header[\"CRVAL1\"] += Shift_1C.deg\n",
    "            hdu.header[\"CRVAL2\"] += Shift_2C.deg\n",
    "        else:\n",
    "            hdu.header[\"CRVAL1\"] += Shift_1.deg\n",
    "            hdu.header[\"CRVAL2\"] += Shift_2.deg\n",
    "\n",
    "        newdata, footprint = reproject.reproject_interp(\n",
    "            hdu,\n",
    "            mosaic_hdr,\n",
    "        )\n",
    "        pieces.append(newdata)\n",
    "    combo = np.nanmedian(\n",
    "        np.stack(pieces),\n",
    "        axis=0,\n",
    "    )\n",
    "    fits.PrimaryHDU(header=mosaic_hdr, data=combo).writeto(outfile, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdaa959",
   "metadata": {},
   "source": [
    "### Same but for continuum files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06465755",
   "metadata": {},
   "outputs": [],
   "source": [
    "afiles = sorted(Path(\"../big-data\").glob(\"lmc-30dor-A-subcube-*-cont.fits\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5492083",
   "metadata": {},
   "outputs": [],
   "source": [
    "afiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d262aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for afile in afiles:\n",
    "    pieces = []\n",
    "    outfile = str(afile).replace(\n",
    "        \"-A-\", \"-ABCD-\"\n",
    "    ).replace(\n",
    "        \"/big-data/\", \"/data/\"\n",
    "    ).replace(\n",
    "        \"-subcube-\", \"-\"\n",
    "    ).replace(\n",
    "        \"-cont\", \"-avcont\"\n",
    "    )\n",
    "    if not update_p(afile, outfile):\n",
    "        continue\n",
    "    print(f\"{afile} -> {outfile}\")\n",
    "    for field in \"ABCD\":\n",
    "        infile = str(afile).replace(\"-A-\", f\"-{field}-\")\n",
    "        ohdu = fits.open(infile)[\"DATA\"]\n",
    "        im = np.mean(ohdu.data, axis=0)\n",
    "        m = (im < 0.0) | (im > 1e6)\n",
    "        im[m] = np.nan\n",
    "        hdu = fits.PrimaryHDU(\n",
    "            data = im,\n",
    "            header = WCS(ohdu.header).celestial.to_header(),\n",
    "        )\n",
    "        if field == \"C\":\n",
    "            hdu.header[\"CRVAL1\"] += Shift_1C.deg\n",
    "            hdu.header[\"CRVAL2\"] += Shift_2C.deg\n",
    "        else:\n",
    "            hdu.header[\"CRVAL1\"] += Shift_1.deg\n",
    "            hdu.header[\"CRVAL2\"] += Shift_2.deg\n",
    "\n",
    "        newdata, footprint = reproject.reproject_interp(\n",
    "            hdu,\n",
    "            mosaic_hdr,\n",
    "        )\n",
    "        pieces.append(newdata)\n",
    "    combo = np.nanmedian(\n",
    "        np.stack(pieces),\n",
    "        axis=0,\n",
    "    )\n",
    "    fits.PrimaryHDU(header=mosaic_hdr, data=combo).writeto(outfile, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea0613f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:light,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
